---
title: (강의) 부분자기상관계수
layout: post
---

### 예비학습 1: Best Predictor

- $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
cov(X,E(Y\|X))=0 
\end{align}

- $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
E\big[(Y-E(Y\|X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
여기에서 $E(Y\|X)$는 best predictor of $Y$ given $X$ 라고 한다. 

### 예비학습 2 

- $Y$, $X$ 가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X+\epsilon
\end{align}
우리의 관심사는 아래를 푸는 것이다. 
\begin{align}
\min_{\beta_0,\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]
\end{align}
따라서 아래를 연립하여 풀면 된다. 
\begin{align}
\frac{1}{\beta_0} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0 \\\\ \\
\frac{1}{\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0
\end{align}
미분을 expectation 안으로 넣으면 
\begin{align}
E\big[-2(Y-\beta_0-\beta_1 X)\big]=0 \\\\ \\
E\big[-2X(Y-\beta_0-\beta_1 X)\big]=0
\end{align}
와 같이 된다. 두번째식을 풀면 
\begin{align}
\beta_1EX^2=EXY-\beta_0EX.
\end{align}
첫번째식을 두번째에 대입하면 
\begin{align}
\beta_1EX^2=EXY-(EY-\beta_1EX)EX=EXY-EXEY+\beta_1(EX)^2.
\end{align}
따라서 
\begin{align}
\beta_1=&\frac{EXY-(EX)(EY)}{EX^2-(EX)^2}=\frac{cov(X,Y)}{V(X)} \\\\ \\
\beta_0=&EY-\frac{cov(X,Y)}{V(X)}EX.
\end{align}

- (예제1) AR(1) 모델의 경우 
\begin{align}
Y_t=\phi Y_{t-1}+\epsilon_t. 
\end{align}
이때 $E\big[(Y_t-\phi Y_{t-1})^2\big]$을 최소화하는 $phi$를 $\hat\phi$이라고 하자. 그러면 
\begin{align}
\hat\phi=\frac{E(Y_tY_{t-1})}{E(Y_{t-1}^2)}
\end{align}


- $Y$, $X_1$, $X_2$가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X_1+\beta_2 X_2+\epsilon
\end{align}
일반적인 회귀분석 셋팅과 다른점은 $X_1$, $X_2$도 확률변수라는 점이다. (이런 점에서 Mixed effect model과 비슷함) 우리의 관심사는 
\begin{align}
\min_{\beta_0,\beta_1,\beta_2} (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2
\end{align}
을 푸는것이다. 즉 아래를 구하는 것이다. 
\begin{align}
\hat{\boldsymbol{\beta} } = (\hat{\beta_0},\hat{\beta_1},\hat{\beta_2})'=\underset{ {\beta_0,\beta_1,\beta_2} }{\operatorname{argmin} }  (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2 
\end{align}
미분을 하면 아래와 같다. 
\begin{align}
sadf
\end{align}