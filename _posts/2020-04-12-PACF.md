---
title: (강의) 부분자기상관계수
layout: post
---

### 예비학습 (Best Predictor)

- $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
cov(X,E(Y\|X))=0 
\end{align}

- $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
E\big[(Y-E(Y\|X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
여기에서 $E(Y\|X)$는 best predictor of $Y$ given $X$ 라고 한다. 

### regression

- $Y$, $X$ 가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X+\epsilon
\end{align}
우리의 관심사는 아래를 푸는 것이다. 
\begin{align}
\min_{\beta_0,\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]
\end{align}
따라서 아래를 연립하여 풀면 된다. 
\begin{align}
\frac{1}{\beta_0} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0 \\\\ \\
\frac{1}{\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0
\end{align}
미분을 expectation 안으로 넣으면 
\begin{align}
\frac{1}{\beta_0} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0 \\\\ \\
\frac{1}{\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0
\end{align}


- $Y$, $X_1$, $X_2$가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X_1+\beta_2 X_2+\epsilon
\end{align}
일반적인 회귀분석 셋팅과 다른점은 $X_1$, $X_2$도 확률변수라는 점이다. (이런 점에서 Mixed effect model과 비슷함) 우리의 관심사는 
\begin{align}
\min_{\beta_0,\beta_1,\beta_2} (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2
\end{align}
을 푸는것이다. 즉 아래를 구하는 것이다. 
\begin{align}
\hat{\boldsymbol{\beta} } = (\hat{\beta_0},\hat{\beta_1},\hat{\beta_2})'=\underset{ {\beta_0,\beta_1,\beta_2} (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2 }{\operatorname{argmin} }
\end{align}
미분을 하면 아래와 같다. 
\begin{align}

\end{align}