---
title: (강의) 부분자기상관계수
layout: post
---

### 예비학습 (Best Predictor)

- 

- $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
E\big[(Y-E(Y\|X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
여기에서 $E(Y\|X)$는 best predictor of $Y$ given $X$ 라고 한다. 

### regression

- $Y$, $X_1$, $X_2$가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X_1+\beta_2 X_2+\epsilon
\end{align}
일반적인 회귀분석 셋팅과 다른점은 $X_1$, $X_2$도 확률변수라는 점이다. (이런 점에서 Mixed effect model과 비슷함) 우리의 관심사는 
\begin{align}
\min_{\beta_0,\beta_1,\beta_2} (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2
\end{align}
을 푸는것이다. 즉 아래를 구하는 것이다. 
\begin{align}
\hat{\boldsymbol{\beta} } = (\beta_0,\beta_1,\beta_2)'=\argmin_{\beta_0,\beta_1,\beta_2} (Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2
\end{align}
