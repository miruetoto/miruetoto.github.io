---
title: (정리) Consistency of MCE
layout: post 
---

### About this post
- 이번에는 **MCE(Minimum Constrast Estimator)**의 **일치성(Consistency)**을 다룬다. 여기에서 콘트라스트(contrast)는 어떤 물체를 다른 물체와 구별가능하게 만드는 시각적인 특성을 의미한다. 보통 콘트라스트(constrast)는 대비, 혹은 명암 등의 의미로 사용되기도 한다. 따라서 **minimum constrast**의 의미는 이러한 시각적 특성의 차이가 최소라는 의미가 된다. 
- 그럼 **MCE** 는 무엇인가? 왜 이런 이름이 붙었는가? 이러한 이름이 붙은 이유를 나름대로 유추해보았는데 대충 다음과 같은 스토리인것 같다. 확률공간 $(\Omega,{\cal F},P_{\theta})$에서 랜덤변수 $X$를 생각하자. 이때 보통 우리는 $\theta$에 관심이 있다. 그런데 이것을 알기 위해서는 $X$의 모든 $\omega \in \Omega$에서의 realization을 모은 집합 $\\{X(\omega), \omega \in \Omega\\}$ 즉 **앙상블**에 대한 통계량을 고려해야 한다. 예를들어 $\theta=(\mu,\sigma^2)$이라면 아래를 계산해야 한다. 
\begin{align}
\mu=\int_{\Omega} X(\omega) dP_{\theta} 
\end{align}
\begin{align}
\sigma^2=\int_{\Omega} X^2(\omega) dP_{\theta} - \left( \int_{\Omega} X(\omega)dP_{\theta} \right)^2
\end{align}
그런데 일단 **앙상블**을 구하는것 자체가 불가능하므로 요건 계산하는것이 불가능하다. 따라서 **앙상블** 대신에 보통 아래와 같은 집합을 얻어서 우리가 알고 싶은걸 구한다. 
\begin{align}
X_1,\dots,X_n \sim i.i.d. ~~ P_{\theta}
\end{align}
집합 $\\{X_i, i \in \mathbb{N}\\}$을 **샘플**이라고 한다. (여기에서 샘플의 원소가 꼭 *i.i.d.*이어야 할것처럼 예를 들었지만 꼭 그런것은 아니다.) 아무튼 각설하고 주된 스토리는 "우리는 **앙상블**을 통해서만 구할수 있는 $\theta$를 알고싶은데 **앙상블**을 못구한다. 그래서 대신 **샘플**을 가지고 $\theta$를 추정하는 estimator $\hat{\theta}$를 구한다."는 것이다. 

- 우리가 구하고 싶은 특정 모수값을 $\theta_0$라고 하자. 또한 $\theta_0$에 대한 추정량으로 $\hat{\theta_0}$를 생각하자. 그럼 $\hat{\theta_0}$을 어떻게 구할까? 이번 포스트에서는 대충 다음과 상황에서 $\theta_0$를 추정한다. **(1)** $\theta_0$는 특정한 식 $D_0(\theta)$를 최소화 하여 구할 수 있음을 알고 있다. **(2)** $\theta_0$는 $D_0(\theta)$를 유일하게 최소화한다. 혹은 유일하게 최소화하는 *compact set* $\cal C$를 잡을 수 있다. 즉 (1)-(2)를 종합하면 우리는 아래식을 만족하는 적당한 $D_0(\theta)$와 *campact set* ${\cal C}$를 알고 있다는 의미이다. 
\begin{align}
\theta = \underset{\theta \in {\cal C}}{\operatorname{argmin}}D_0(\theta)
\end{align}
예를들어 우리는 회귀분석의 상황에서 아래식이 성립함을 이미 알고 있다. 
\begin{align}
\beta = \underset{\beta \in \mathbb{R}}{\operatorname{argmin}}D_0(\theta) =  \underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E(y-x\beta)^2
\end{align}
**(3)** 아래식을 만족하는 $D_n(\theta)$를 우리가 이미 알고 있다. 
\begin{align}
\underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_n(\theta) - D_0(\theta)\right|  \overset{p_{\theta}}{\rightarrow} 0  ~~ as ~ n\rightarrow \infty
\end{align}

- 이중에서 **(3)** 의 조건은 상당히 가혹하다. 한번 생각해보자. $D_0(\theta)$는 **앙상블**이 있어야 구할 수 있다. **앙상블**은 우리가 실제 구할 수 없는 집합이므로 $D_0(\theta)$의 **샘플**버전 $D_n(\theta)$가 필요하다. **샘플**버전은 항상 샘플크기 $n$이 커질수록 **앙상블**과 비슷해져야하는 것이 바람직하다. 따라서 $\theta \in {\cal C}$에서 아래 정도의 조건을 주는것은 reasonable하다. 
\begin{align}
D_n(\theta)  \overset{p_{\theta}}{\rightarrow} D_0(\theta)  ~~ as ~ n\rightarrow \infty
\end{align}

- 아무튼 이러한 조건하에서는 아래가 성립함을 주장할 수 있다. 
\begin{align}
\theta_n \overset{p_{\theta}}{\rightarrow} \theta_0
\end{align}

- ***(Proof : case 1)*** 이제 증명을 하여보자. 먼저 편의상 $D_n$과 $D_0$가 모두 랜덤이 아니라고 생각하여 보자. $D_n$과 $D_0$이 랜덤이 아니기 때문에 
\begin{align}
\underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_n(\theta) - D_0(\theta)\right|  \overset{p_{\theta}}{\rightarrow} 0  ~~ as ~ n\rightarrow \infty
\end{align}
의 조건은 아래와 같이 재정리된다. 
\begin{align}
\underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_n - D_0\right| \rightarrow 0  ~~ as ~ n\rightarrow \infty
\end{align}
또한 
\begin{align}
\theta_n \overset{p_{\theta}}{\rightarrow} \theta_0
\end{align}
역시 
\begin{align}
\theta_n \rightarrow \theta_0
\end{align}
로 변경된다. 즉 확률수렴에 관련된 부분들이 모두 일반수렴으로 변화하게 된다. 정리하면 아래의 조건에서 
\begin{align}
\theta = \underset{\theta \in {\cal C}}{\operatorname{argmin}}D_0(\theta)
\end{align}
\begin{align}
\theta_n = \underset{\theta \in {\cal C}}{\operatorname{argmin}}D_n(\theta)
\end{align}
\begin{align}
\underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_n - D_0\right| \rightarrow 0  ~~ as ~ n\rightarrow \infty
\end{align}
아래를 증명하면 된다. 
\begin{align}
\theta_n \rightarrow \theta_0
\end{align}
귀류법을 쓰기위해 $\theta_n \rightarrow \theta_0$가 아니라고 생각하자. 그러면 
\begin{align}
|\theta_n - \theta_0|>\epsilon ,~ i.o.
\end{align}
가 되도록 하는 적당한 $\epsilon>0$이 존재한다. 위의 식의 의미는 무엇일까? $\theta_n$이 $\theta_0$로 수렴하지 않는다고 주장하고 있으므로 아무리 $n \rightarrow \infty$인 상황에서도 절대로 $\theta_n$은 $\theta_0$로 가까이 가지 않는다. 즉 $\theta_0$주위에 적당한 반경 $\epsilon>0$을 잡았다고 할때 이 반경안에 $\theta_n$가 가끔씩 들어올수는 있을 지언정 항상 그 반경안에 들어오지는 않는다는 것이다. 즉 *i.o.*하게 반경밖으로 벗어난다. 편의상 이러한 반경을 ${\cal B}:=\\{\theta:|\theta_0-\theta|>\epsilon \\}$라고 하자. 
이제
\begin{align}
\underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_n(\theta) - D_0(\theta)\right|
\end{align}
을 편의상 $\Delta_n$이라고 정의하자. 즉 $\Delta_n$은 **앙상블**에서의 콘트라스트 함수와 **샘플**에서의 콘트라스트 함수간의 차이를 each point $\theta \in {\cal C}$에서 구한것들의 최대값을 의미한다. 증명은 아래 식이 성립함을 이해하는 것에서 시작한다.  
\begin{align}
\underset{\theta \notin {\cal B}}{\operatorname{inf}} D_0(\theta) -\underset{\theta \notin {\cal B}}{\operatorname{inf}} D_n(
\theta) \leq \Delta_n
\end{align}
아래와 같은 논리로 이해하면 될것 같다. 
\begin{align}
\underset{\theta \notin {\cal B}}{\operatorname{inf}} D_0(\theta) -\underset{\theta \notin {\cal B}}{\operatorname{inf}} D_n(\theta)  \leq \underset{\theta \in {\cal C}}{\operatorname{sup}} \left|\underset{\theta \notin {\cal B}}{\operatorname{inf}} D_0(\theta)-D_n(\theta)  \right| \leq \underset{\theta \in {\cal C}}{\operatorname{sup}}\left|D_0(\theta) - D_n(\theta)\right| = \Delta_n
\end{align}
