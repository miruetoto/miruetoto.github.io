---
title: (리뷰) AK, ENAS with NM
layout: post 
--- 

### About this doc

- 이 포스트는 아래논문의 리뷰이다. <br/>
Jin, H., Song, Q., & Hu, X. (2018). Auto-keras: Efficient neural architecture search with network morphism. arXiv preprint arXiv:1806.10282.

### AK: ENAS with NM

- 기븐 neural architecture search space 를 ${\cal F}$ 라고 하자. 입력자료를 $X$ 라고 하고 cost metric 을 $Cost(\cdot)$ 이라고 하자. 우리의 목표는 최적의 뉴럴네트워크 $f^* \in {\cal F}$ 를 찾는것이다. 이때 네트워크 $f $ 의 훈련파라메터는 $\theta_f $라고 한다. 따라서 아래를 푸는것에 관심을 가진다. 
\begin{align}
f^* = \underset{f \in {\cal F} }{\operatorname {argmin} } \min_ {\theta_f } Cost(f(X; \theta_f))
\end{align}
여기에서 $\theta_f \in \mathbb{R}^{w(f)}$ 이고 $w(f)$는 $f$ 에 속하는 파라메터의 갯수이다. 

- 네트워크 $f$의 구조를 directed acyclic graph $G_f=(V_f,E_f)$ 로 표현하자. 임의의 두 노드 $v,u \in V_f$ 사이에서 
\begin{align}
u \prec v 
\end{align}
가 성립한다는 것은 노드 $v$에서 적당히 에지를 따라서 흘러가면 $u$에 도달(reachable)할 수 있다는 의미이다. 그리고 이 논문에서는 모든노드에 대하여 $u \prec v$ 이거나 $v \prec u$ 임을 가정하자. (즉 모든 노드가 연결되어있다는 의미임.) 

- 2개의 뉴럴네트워크 $f_a$, $f_b$ 가 있다고 하자. 아래와 같은 커널을 생각하자. 
\begin{align}
\kappa(f_a, f_b)=e^{-\rho^2 (d(f_a,f_b))}
\end{align}
여기에서 $d$는 사용자가 정의하기 나름인 거리함수이고 $\rho$ 는 (결과를 잘나오게끔 조절가능한) 적당한 mapping 함수이다. 

- 논문에서 제안하는 방법은 결국 아래와 같다. 
\begin{align}
d(f_a,f_b)=D_l(L_a,L_b)+\lambda D_s(S_a,S_b).
\end{align}
여기에서 $L_a, L_b$ 는 각각 $f_a$ 와 $f_b$ 에 포함된 네트워크를 레이어 별로 묶은 것이다. 즉 $L_a=\\{l_a^{(1)},l_a^{(2)},\dots,\\}$ 이고 $L_b=\\{l_b^{(1)},l_b^{(2)},\dots,\\}$ 이다. 

- 이제 적절한 네트워크를 선택하는 방법을 생각하여 보자. 아래를 정의하자. 
\begin{align}
y_f=\min_{\theta_f} Cost(f(X;\theta_f))
\end{align}
여기에서 $y_f$ 는 평균이 $\mu(y_f)$ 이고 분산이 $\sigma(y_f)$ 인 확률변수라고 가정한다. 그럼 아래와 같이 $y_f$의 lowest possible value 를 정의할 수 있다. 
\begin{align}
\alpha(f) = \mu(y_f) -\beta \sigma(y_f)
\end{align}
여기에서 $\beta$ 는 balancing factor 라고 한다. 이는 탐험의 정도를 조절하는 변수로도 해석가능하다. 

- 새로운 아키텍처는 아래를 풀어서 얻을 수 있다. 
\begin{align}
\hat{f} = \underset{f}{\operatorname {argmin} } \alpha(f)
\end{align
이때 $f$ 가 살고있는 공간을 ***tree-structred space*** 라고 논문에서 표현하였다. 여기에서는 가능한 모든 $f$를 고려한것은 아니다. 대신에 어떠한 선별된 아키텍처들의 집합 $\\{f_1,\dots,f_m\\}$ 에서 특정 오퍼레이션들의 집합 $\Omega(f)$ 로 부터 모핑가능한 네트워크들만 고려한다. 이 과정을 서술한것이 알고리즘 1이다. 여기에서 오퍼레이션들의 집합 $\Omega(f)$ 은 ***deep, wide, add, concat*** 
 4개로 구성되는것 같다. 이과정들에 대한 자세한 설명이 3.3에 서술되어있다. 

### 결론 및 요약

- 이 논문의 최적의 아키텍처를 찾는 방법을 다룬 논문이다. 

- 아키텍처는 방향성그래프(DAG)로 표현가능한 어떠한 아키텍처도 상관이 없다. 

- 논문은 특정한 아키텍처를 처음부터 만들지는 않는다는 점에서 NAS와 차별성을 가진다. (NAS는 처음부터 아키텍처를 RNN으로 컨스트럭트함) 대신에 논문은 이미 알고있는 아키텍처를 조금 변형하여(논문에서는 이걸 모핑이라고 한다) 새로운 아키텍처를 생성해 낸다. 

- 기존의 아키텍처 A와 모핑된 아키텍처 A'은 서로 어느정도는 비슷해야 한다. (완전히 쌩뚱맞은 아키텍처를 뱉어낼 수 없음.) 여기에서 아키텍처간의 '비슷함' 을 측정하기 위해서 저자들은 새로운 거리를 제안한다. 그리고 그 거리의 단점을 보완하기 위한 커널도 새롭게 제안한다. 이는 논문의 수식 (2) 와 (3) 에 제시되어 있으며 이 값들을 계산하여 A 에서 A' 을 만들어내는 방법을 제안하는 기초를 마련하였다. 

- 논문에서는 보상값이 랜덤이라는 점에서도 NAS와 차이점을 가진다. 나스에서는 엔바이런먼트가 주는 보상값이 고정된 값인데 여기서는 랜덤값이라고 생각한다. 

- 보상값이 랜덤이므로 그것의 평균과 분산이 존재한다. 따라서 새롭게 생성되는 아키텍처들의 모임 각각에 대한 코스트의 평균과 분산을 마치 베이지안 옵티마이제이션에 잘나오는 그림 마냥 그릴 수 있다. 

- 당연히 보상값이 최대가 되는 아키텍처를 고르는것이 유리한데 여기에서 특이한 점은 평균뿐만 아니라 분산까지 고려하여 탐험의 비율을 조절할 수 있게 하였다는 점이다. 

- 베이지안 옵티마이징과 차이점은 다음과 같다. (1) 베이지안 옵티마이징에서 관심이 있는 타겟펑션은 실수에서 실수로 가는 함수이지만 여기에서 관심을 가지는 타겟펑션은 아키텍처에서 실수로 가는 함수이다. (2) 베이지안 옵티마이징에서는 타겟펑션의 정의역이 변화하지 않지만 여기에서는 변화한다. (3) 베이지안 옵티마이징에서는 정의역이 연속이지만 여기에서는 디스크릭하다. (따라서 최소값 찾는건 겁나쉽다) (4) 베이지안 옵티마이징에서는 타겟펑션의 모양 자체를 학습하는데 초점을 맞추지만 (최저값을 찾는건 부수적인 문제) 여기에서는 최소값을 찾는거 자체가 고민이다. (5) (4)의 이유로 베이지안 옵티마이징에서는 우선 포스테리어의 분산이 맥시마이즈되는 지점을 "선택"하여 탐사한다. 하지만 논문의 방법에서는 "지정"된 지점을 탐사하며 평균이 작고 분산이 큰 지점을 탐사한다. (평균과 분산의 관계는 베타로 조정한다) 

- 논문의 알고리즘은 (1) 생성 (2) 평가 (3) 업데이트 의 과정을 반복하면서 그런데 후반부로 갈수록 업데이트가 되는 비율이 점점 낮아진다. 따라서 알고리즘 1은 항상 수렴한다. 

- 위와 같은 이유로 알고리즘이 수렴하지 않다가 갑자기 어느 순간 잠재력이 터지면서 갑자기 수렴하기 시작하는 현상은 관측되지 않는다. 대부분 초반 몇번의 이터레이션에 성능평가가 날것이다. 

- 아키텍처에서 모핑된 새로운 후보들이 시원치 않을경우 업데이트를 안할수도 있다. 

- 모핑을 하는 방식은  ***deep, wide, add, concat*** 이며 이 방식은 추가되거나 수정될 수 있다. 

- 이 방식이 RNN 에서 효과적일것 같지는 않다. 

- 이론적이지 않지만 실용적으로 보인다. 












