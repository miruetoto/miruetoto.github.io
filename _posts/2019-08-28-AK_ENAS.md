---
title: (리뷰) AK, ENAS with NM
layout: post 
--- 

### About this doc

- 이 포스트는 아래논문의 리뷰이다. <br/>
Jin, H., Song, Q., & Hu, X. (2018). Auto-keras: Efficient neural architecture search with network morphism. arXiv preprint arXiv:1806.10282.

### AK: ENAS with NM

- 기븐 neural architecture search space 를 ${\cal F}$ 라고 하자. 입력자료를 $X$ 라고 하고 cost metric 을 $Cost(\cdot)$ 이라고 하자. 우리의 목표는 최적의 뉴럴네트워크 $f^* \in {\cal F}$ 를 찾는것이다. 이때 네트워크 $f $ 의 훈련파라메터는 $\theta_f $라고 한다. 따라서 아래를 푸는것에 관심을 가진다. 
\begin{align}
f^* = \underset{f \in {\cal F} }{\operatorname {argmin} } \min_ {\theta_f } Cost(f(X; \theta_f))
\end{align}
여기에서 $\theta_f \in \mathbb{R}^{w(f)}$ 이고 $w(f)$는 $f$ 에 속하는 파라메터의 갯수이다. 

- 네트워크 $f$의 구조를 directed acyclic graph $G_f=(V_f,E_f)$ 로 표현하자. 임의의 두 노드 $v,u \in V_f$ 사이에서 
\begin{align}
u \prec v 
\end{align}
가 성립한다는 것은 노드 $v$에서 적당히 에지를 따라서 흘러가면 $u$에 도달(reachable)할 수 있다는 의미이다. 그리고 이 논문에서는 모든노드에 대하여 $u \prec v$ 이거나 $v \prec u$ 임을 가정하자. (즉 모든 노드가 연결되어있다는 의미임.) 

- 2개의 뉴럴네트워크 $f_a$, $f_b$ 가 있다고 하자. 아래와 같은 커널을 생각하자. 
\begin{align}
\kappa(f_a, f_b)=e^{-\rho^2 (d(f_a,f_b))}
\end{align}
여기에서 $d$는 사용자가 정의하기 나름인 거리함수이고 $\rho$ 는 (결과를 잘나오게끔 조절가능한) 적당한 mapping 함수이다. 

- 논문에서 제안하는 방법은 결국 아래와 같다. 
\begin{align}
d(f_a,f_b)=D_l(L_a,L_b)+\lambda D_s(S_a,S_b).
\end{align}
여기에서 $L_a, L_b$ 는 각각 $f_a$ 와 $f_b$ 에 포함된 네트워크를 레이어 별로 묶은 것이다. 즉 $L_a=\\{l_a^{(1)},l_a^{(2)},\dots,\\}$ 이고 $L_b=\\{l_b^{(1)},l_b^{(2)},\dots,\\}$ 이다. 

- 이제 적절한 네트워크를 선택하는 방법을 생각하여 보자. 아래를 정의하자. 
\begin{align}
y_f=\min_{\theta_f} Cost(f(X;\theta_f))
\end{align}
여기에서 $y_f$ 는 평균이 $\mu(y_f)$ 이고 분산이 $\sigma(y_f)$ 인 확률변수라고 가정한다. 그럼 아래와 같이 $y_f$의 lowest possible value 를 정의할 수 있다. 
\begin{align}
\alpha(f) = \mu(y_f) -\beta \sigma(y_f)
\end{align}
여기에서 $\beta$ 는 balancing factor 라고 한다. 이는 탐험의 정도를 조절하는 변수로도 해석가능하다. 

- 새로운 아키텍처는 아래를 풀어서 얻을 수 있다. 
\begin{align}
\hat{f} = \underset{f}{\operatorname {argmin} } \alpha(f)
\end{align
이때 $f$ 가 살고있는 공간을 ***tree-structred space*** 라고 논문에서 표현하였다. 여기에서는 가능한 모든 $f$를 고려한것은 아니다. 대신에 어떠한 선별된 아키텍처들의 집합 $\\{f_1,\dots,f_m\\}$ 에서 특정 오퍼레이션들의 집합 $\Omega(f)$ 로 부터 모핑가능한 네트워크들만 고려한다. 이 과정을 서술한것이 알고리즘 1이다. 여기에서 오퍼레이션들의 집합 $\Omega(f)$ 은 ***deep, wide, add, concat*** 
 4개로 구성되는것 같다. 이과정들에 대한 자세한 설명이 3.3에 서술되어있다. 

### 결론 및 요약

- 










