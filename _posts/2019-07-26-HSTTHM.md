---
title : (논문) Theory of HST 
layout: post 
---

### About this doc

- 이 문서에서는 HST에 대한 몇 가지 이론적 성질들을 struct 한다. 

### HST 

- 그래프형태의 자료 $(V,E,f(V))$에서의 hst를 $(V,E,\boldsymbol{h}(V))$라고 정의하자. 각각의 $i=1,\dots,n$에 대하여 $\boldsymbol{h}(v_i)$ 는 크기가 $1\times (\tau+1)$인 벡터이다. 각각의 $i,j \in \\{1,\dots,n\\}$ 에 대하여 노드 $v_i$, $v_j$ 간의 snow-dist는 아래와 같이 정의한다. 
\begin{align}
sdist(v_i,v_j) := \\|\boldsymbol{h}(v_i)-\boldsymbol{h}(v_j) \\|_ 2^2 
\end{align}
각각의 노드에 새롭게 쌓인 눈의 양만을 알고 싶다면 아래를 살펴보는 것도 좋다. 
\begin{align}
\boldsymbol{\dot h}(v_1), \dots, \boldsymbol{\dot h}(v_n).
\end{align}
이것은 각각 $\boldsymbol{h}(v_1),\dots,\boldsymbol{h}(v_n)$ 을 차분해서 얻을 수 있는 길이가 $1\times \tau$ 벡터이다. 

- 각 노드에 내리는 눈의 양을 $\epsilon_i=\epsilon(v_i)$ 라고 하자. 눈이 내린 횟수 $\ell$ 을 고정하였을때, $v_i$ 지역으로 눈을 흘려보낼 수 있는 지역들의 모임을 ${\cal N}(i,\ell)$ 라고 하고 엄밀하게는 아래와 같이 정의하자. 
\begin{align}
{\cal N}(i,\ell) := \Big\\{j:(i,j)\in E , ~ h^{\ell}(v_i)+\epsilon(v_i) \leq h^{\ell}(v_j) \Big\\} 
\end{align}
이때 ${\cal N}(i,\ell)$ 은 ${\cal N}_ {v_i}:={\cal N}_ i:=\\{j: (i,j)\in E \\}$ 와는 다름을 유의하라. 각 노드에 쌓인 눈의 양을 아래와 같이 정의할 수 있다. 
\begin{align}
h^{\ell}(v_i)&=h^{\ell-1}(v_i)+ \sum_{j \in {\cal N}(i,\ell-1)}\Big( \frac{\epsilon(v_j)}{\|{\cal N}_ j \| }+\frac{\epsilon(v_i)}{\|{\cal N}_ i \| }\Big)  \\\\ \\ 
&= h^{\ell-1}(v_i)+ \frac{\epsilon(v_i)}{\|{\cal N}_ i \| }\|{\cal N}(i,\ell-1)\|+ \sum_{j \in {\cal N}(i,\ell-1)} \frac{\epsilon(v_j)}{\|{\cal N}_ j \| }
\end{align}

- HST를 매트릭스를 이용하여 정의하여 보자. $\ell = 0,1,2,\dots $ 에 대하여 ${\boldsymbol h}^{\ell}$ 을 각각 길이가 $n$인 벡터라고 하자. 그리고 $n\times n$ 매트릭스 ${\bf A}^{(\ell)}$ 를 아래와 같이 정의하자. 
\begin{align}
{\bf A}^{(\ell)}_ {ij}=
\begin{cases} 
\frac{ 1_ { {\cal N}(i,\ell-1) }(j)}{\|{\cal N}_ j\|}  & i \neq j  \\\\ \\
\frac{\|{\cal N}(i,\ell-1)\|}{\|{\cal N}_ i\|} & i=j
\end{cases} 
\end{align}
여기에서 
\begin{align}
1_A(x)=
\begin{cases}
1 & x \in A \\\\ \\
0 & x \notin A 
\end{cases}
\end{align} 
이다. 이제 $\ell = 1,2,\dots $ 에 대하여 ${\boldsymbol f}=(f(v1),\dots,f(v_n))'$ 의 HST 를 아래와 같이 정의할 수 있다. 
\begin{align}
{\boldsymbol h}^{\ell}= {\bf A}^{(\ell)} {\boldsymbol \epsilon}+ {\boldsymbol h}^{\ell-1} 
\end{align}


### Model and Assumption 

- 그래프 ${\cal G}=(V,E)$는 어떠한 매니폴드의 ${\cal M}$ 의 ***sample version*** 이다. 이는 마치 ***continuous component*** 에서 ***discrete componet*** 를 얻는과정과 비슷하다. 여기에서 $E$대신에 ${\cal G}=(V,W)$와 같이 정의할 수도있다. (원래는 보통 ${\cal G}=(V,E,W)$로 정의함. 그런데 사실 $W$에 대한 정보만 있어도 $E$를 추론하는것은 어렵지 않은것 같다) 만약에 ${\cal M}$이 리만매니폴드이고 ${\cal G}$가 ${\cal M}$의 regural smample 이라면 ${\cal G} \to {\cal M}$ 

- ***modeling.*** 그래프 ${\cal G}=(V,E)$가 어떠한 매니폴드 ${\cal M}$ nerate 된 realization 이라고 하자. 그래프 $(V,E)$ 가 ***given*** 일때 각각의 노드 $v_i$에서 정의되는 확률변수 $f(v_i)$는 아래와 같은 분포를 가진다고 가정하자. 
\begin{align}
f(v_i) \sim F_{\theta_i}
\end{align}
그리고 아래를 만족하는 함수 $g$ 가 존재하는 ***scale*** $\tau$ 가 $\\{0\\} \cup \mathbb{N}$ 중에서 적어도 하나이상은 있다고 하자. (**그리고 이러한 $g$ 가 존재하는 $\tau$ 들의 집합을 ${\cal T}^* $ 라고 하자.**)  
\begin{align}
\theta_i=g\big({\boldsymbol \theta}_ {(-i)},\boldsymbol{\dot h}_ {(-i)} \big)
\end{align}
여기에서 $\tau=0$ 이면 $\theta_i=g\big({\boldsymbol \theta}_ {(-i)}\big)$ 이다. 그리고 
\begin{align}
\begin{cases}
{\boldsymbol \theta}_ {(-i)}:=(\theta_1,\dots,\theta_{i-1},\theta_{i+1},\dots,\theta_n)  \\\\ \\
\boldsymbol{\dot h}_ {(-i)}:=(\boldsymbol{\dot h}_ 1,\dots,\boldsymbol{\dot h}_ {i-1},\boldsymbol{\dot h}_ {i+1},\dots,\boldsymbol{\dot h}_ n) 
\end{cases}
\end{align}
이다. 

### Regular graph

- ***claim 1.*** 각각의 노드 $v_i$에서 정의된 확률변수 $f(v_i)$가 서로 독립이고 같은분포를 가진다고 하자. 그리고 $(V,E)$ 가 ***regular graph*** 라고 하자. 그리고 아래를 가정하자. 
\begin{align}
f(v_1),\dots f(v_n) ~ \sim ~ i.i.d. ~ F\big(f(v);\theta\big)
\end{align} 
그러면 모든 $\tau \in \mathbb{N}$ 에 대하여 각 $v_i$에 대응하는 확률벡터 $\boldsymbol{\dot h}(v_i)$ 역시 서로 독립이고 같은 분포를 가진다. 즉  \begin{align}
\boldsymbol{\dot h}(v_1),\dots \boldsymbol{\dot h}(v_n) ~ \sim ~ i.i.d. ~ G\big(\boldsymbol{\dot h}(v);\eta\big)
\end{align}
이다. 이때 $F:\mathbb{R} \to \mathbb{R}$ 이고 $G: \mathbb{R}^{\tau} \to \mathbb{R}$ 임을 유의하라. 

- 적당한 매니폴드 ${\cal M}$ 이 있다고 하자. $T$를 분포 $G$에서 $\mathbb{R}$ 로 가는 ***functional*** 이라고 하자. 여기에서
\begin{align}
T(G;{\cal M})=\mathbb{E} \\| {u\in {\cal M}_ v} \boldsymbol{\dot h}(v)-\boldsymbol{\dot h}(u) \\|_ 2^2 
\end{align}
라고 두고 싶다. 그런데 $T(G;E)$ 가 ***Fisher consistent*** 를 만족하려면 
\begin{align}
T(G)=\mathbb{E} \\| \frac{1}{\|{\cal N}_ v\|}\sum_{u\in {\cal N}_ v} \boldsymbol{\dot h}(v)-\boldsymbol{\dot h}(u) \\|_ 2^2 = \theta
\end{align}
라고 둘 수 있어야 하는데 이것이 좀 애매한게 $\boldsymbol{\dot h}(v)$ 의 분포를 결정짓는 파라메터가 $\theta$ 이라는게 좀 걸린다. 아무튼 이렇게 둘 수 있다면 ***given data*** 가 있을때 아래와 같이 정의할 수 있다. 
\begin{align}
T(G_n ; E)=\mathbb{E} \\| \frac{1}{\|{\cal N}_ v\|}\sum_{u\in {\cal N}_ v} \boldsymbol{\dot h}(v)-\boldsymbol{\dot h}(u) \\|_ 2^2 
\end{align}

- 여기에서 $\mathbb{E} \\| \boldsymbol{\dot h}(v_i)-\boldsymbol{\dot h}(v_j) \\|_ 2^2$ 는 ***quadratic form of graph Laplacian*** 이다.

- $G_n$을 벡터 $\boldsymbol{\dot h}(v_1),\dots,\boldsymbol{\dot h}(v_n)$에 대응하는 empirical-cdf 라고 하자. 우리가 regular graph 를 가정하였으므로 ***claim 1*** 에 의해서 $\boldsymbol{\dot h}(v_1),\dots \boldsymbol{\dot h}(v_n)$ 역시 ***i.i.d.*** 가 될것이고 따라서 글리벤코-칸텔리 정리를 쓸 수 있을 것이다. 글리벤코-칸텔리정리는 $G_n \to G$ 임을 보여준다. 따라서 적당히 큰 $n$에 대하여 $G_n$은 $G$의 neighborhood에 속한다고 볼 수 있다. 따라서 
\begin{align}
T(G_n) & \approx  T(G)+\int IF(x,T,G)d(G_n-G)(x) \\\\ \\ 
& = T(G)+\int IF(x,T,G) dG_n(x) 
\end{align}
이다. 여기에서 $\int IF(x,T,G)dG(x)=0$ 임이 사용되었다. 따라서 
\begin{align}
\sqrt{n}\Big(T(G_n)-T(G) \Big) \to N(0,V(T,G))
\end{align}
이다. 여기에서 $V(T,G)=\int IF(x,T,G)^2 dG(x)$ 이다. 

- 
