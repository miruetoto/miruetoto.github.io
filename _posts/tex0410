\section*{Appendix}
\subsubsection*{A.1. Proof of Proposition~\ref{variancemax}}
\begin{proof} 
\textcolor{red}{
For fixed $i$ and $\ell$ there exist $\tilde \ell \in \{1,\dots,\tau \}$ such that 
\begin{align*}
X_{i}^{\ell,\tau}=\frac{\tilde \ell X_{i+\tilde \ell-\tau}+ (\tau-\tilde \ell)X_{i+\tilde \ell}}{\tau}. 
\end{align*}
Thus $M_i^{{\bf X},\tau}$ can be expressed as 
\begin{align*}
M_i^{{\bf X},\tau}
=\frac{1}{\tau}\sum_{\ell=1}^{\tau} \frac{\ell X_{i+\ell-\tau}+ (\tau-\ell)X_{i+\ell}}{\tau}
=\frac{1}{\tau^2}\sum_{\ell=1}^{\tau} \ell X_{i+\ell-\tau}
	+ \frac{1}{\tau^2}\sum_{\ell=1}^{\tau}(\tau-\ell)X_{i+\ell}.
\end{align*}
In here 
\begin{align*}
\sum_{\ell=1}^{\tau} \ell X_{i+\ell-\tau}=\sum_{k=i-\tau+1}^{i} (\tau+(k-i)) X_{k}
\end{align*}
and 
\begin{align*}
\sum_{\ell=1}^{\tau} (\tau-\ell) X_{i+\ell}=\sum_{k=i+1}^{i+\tau} (\tau-(k-i)) X_{k}.
\end{align*}
Thus 
\begin{align*}
M_i^{{\bf X},\tau}
&=\sum_{k=i-\tau+1}^{i} \frac{\tau+(k-i)}{\tau^2} X_{k}
+\sum_{k=i+1}^{i+\tau} \frac{\tau-(k-i)}{\tau^2} X_{k}
=\sum_{k=i-\tau+1}^{i+\tau} \frac{\tau-|k-i|}{\tau^2} X_{k}  \\ 
&=\sum_{k=i-\tau+1}^{i+\tau-1} \frac{\tau-|k-i|}{\tau^2} X_{k}.
\end{align*}
For fixed $i$, $V_{i}^{{\bf X},\tau}$ can be expressed as 
\begin{align*}
V_{i}^{{\bf X},\tau}
&=\frac{1}{\tau-1}\sum_{\ell=1}^{\tau}\left(X_i^{\ell,\tau}-M_i^{{\bf X},\tau} \right)^2
=\frac{1}{\tau-1}\sum_{\ell=1}^{\tau}\left(X_i^{\ell,\tau}\right)^2-\frac{\tau}{\tau-1}\left(M_i^{{\bf X},\tau} \right)^2.
\end{align*}
In here 
\begin{align*}
\sum_{\ell=1}^{\tau}\left(X_i^{\ell,\tau}\right)^2 
&=\sum_{\ell=1}^{\tau}\left(\frac{\ell X_{i+\ell-\tau}+ (\tau-\ell)X_{i+\ell}}{\tau}  \right)^2 \\ 
&=\sum_{\ell=1}^{\tau}\frac{\ell^2}{\tau^2} X_{i+\ell-\tau}^2 
+ \sum_{\ell=1}^{\tau}\frac{(\tau-\ell)^2}{\tau^2}X_{i+\ell}^2 
+ \sum_{\ell=1}^{\tau}\frac{2\ell(\tau-\ell)}{\tau^2}X_{i+\ell-\tau}X_{i+\ell}.
\end{align*}
Note that first two terms can be summarized as
\begin{align*}
\sum_{\ell=1}^{\tau} & \frac{\ell^2}{\tau^2} X_{i+\ell-\tau}^2 
+ \sum_{\ell=1}^{\tau}\frac{(\tau-\ell)^2}{\tau^2}X_{i+\ell}^2 \\
&=\sum_{m=i-\tau+1}^{i}\frac{(\tau+(m-i))^2}{\tau^2} X_m^2 
+ \sum_{m=i+1}^{i+\tau-1}\frac{(\tau-(m-i))^2}{\tau^2}X_m^2 \\  
&=\sum_{m=i-\tau+1}^{i+\tau-1}\frac{(\tau-|m-i|)^2}{\tau^2} X_m^2 \\
&=\sum_{m,k=i-\tau+1}^{i+\tau-1}\tilde a_{m,k} X_mX_k 
\end{align*}
where 
\[
\tilde a_{m,k}=\begin{cases} 
\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^2}&  |m-k|=0 \\ 
0 & \mbox{otherwise}.
\end{cases}
\]
and last term can be summarized as 
\begin{align*}
\sum_{\ell=1}^{\tau}\frac{2\ell(\tau-\ell)}{\tau^2}X_{i+\ell-\tau}X_{i+\ell}=\sum_{m,k=i-\tau+1}^{i+\tau-1}\tilde b_{m,k}X_mX_k
\end{align*}
where 
\[
\tilde b_{m,k}=\begin{cases} 
\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^2}&  |m-k|=\tau \\ 
0 & \mbox{otherwise}. 
\end{cases}
\]
The term $\left(M_i^{{\bf X},\tau} \right)^2$ can be expressed as 
\begin{align*}
\left(M_i^{{\bf X},\tau} \right)^2=\sum_{m,k=i-\tau+1}^{i+\tau-1}\tilde c_{m,k}X_mX_k
\end{align*}
where 
\[
\tilde c_{m,k}=\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^4}.
\]
Thus 
\begin{align*}
V_{i}^{{\bf X},\tau}=\sum_{m,k=i-\tau+1}^{i+\tau-1}\left(\frac{\tilde a_{m,k}+\tilde b_{m,k}}{\tau-1}-\frac{\tau\tilde c_{m,k}}{\tau-1}\right)X_mX_k.
\end{align*}
If $|m-k|=0$ or $|m-k|=\tau$ then coefficient of $X_mX_k$ is
\begin{align*}
\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^2(\tau-1)}-\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^3(\tau-1)}=\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^3}. 
\end{align*}
If $|m-k|\notin \{0,\tau\}$ then coefficient of $X_mX_k$ is just $\frac{-\tau\tilde c_{m,k}}{\tau-1}$, i.e.,
\begin{align*}
-\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^3(\tau-1)}.
\end{align*}
} %End of textcolor
Thus by a simple (but tedious) algebra with the definition of elastic-band, $E\big[V_i^{{\bf X},\tau}\big]$ can be expressed as
\[
E\left[V_i^{{\bf X},\tau}\right]=\sum_{m,k=i-\tau+1}^{i+\tau-1}a_{m,k}E(X_mX_k)
\]
with 
\[
a_{m,k}=\begin{cases} 
\frac{(\tau-|m-i|)(\tau-|k-i|)}{\tau^3}&  |m-k|=0,~\tau \\ 
\frac{-(\tau-|m-i|)(\tau-|k-i|)}{\tau^3(\tau-1)} & \mbox{otherwise}
\end{cases}
\]
Note that $E(X_mX_k)=\mu_m\mu_k$ for $m\neq k$ and  $E(X_m^2)=\sigma^2+\mu_m^2$ otherwise, where $\mu_k:=E(X_m)$ and $\sigma^2:=Var(X_m)$. From the fact that $\mu_{m}=\mu_{m+\xi}$, it follows that 
\begin{eqnarray*}
E\left[V_i^{{\bf X},\tau}\right]&=&\sum_{\underset{m\neq k}{m,k=i-\tau+1}}^{i+\tau-1}a_{m,k}\mu_m\mu_k+\sum_{m=i-\tau+1}^{i+\tau-1}a_{m,m}(\sigma^2+\mu_m^2)\\ 
	&=&\sum_{\underset{m\neq k}{m,k=i}}^{i+\xi-1}b_{m,k}\mu_m\mu_k+\sum_{m=i}^{i+\xi-1}b_{m,m}(\sigma^2+\mu_m^2),
\end{eqnarray*}
where $b_{m,k}=\sum_{(z_1,z_2)\in Z_1\times Z_2}a_{m+z_1\xi,k+z_2\xi}$, $Z_1=\left\{z_1: |i-(m+z_1\xi)|<\tau, z_1\in\mathbb{Z}\right\}$, and $Z_2=\left\{z_2: |i-(k+z_2\xi)|<\tau, z_2\in\mathbb{Z} \right\}$. Note that $z_1$ and $z_2$ can take values only $\{-1,0,1\}$ since $\tau<2\xi$. It can be easily obtained that $b_{m,k}$ satisfy the following three conditions: (i) $\sum_{k=i}^{i+\xi-1}b_{m,k}=0$, (ii) $\sum_{l=i}^{i+\xi-1}b_{l,m}=0$, and (iii) $0\le b_{m,m}\le \frac{1}{\tau}$.  

In order to maximize $E\big[{\bf V}^{{\bf X},\tau}\big]$ subject to the three conditions (i)--(iii), we consider the following Lagrangian $\cal L$
\begin{align*}
{\cal L}&=\sum_{\underset{m\neq k}{m,k=i}}^{i+\xi-1}b_{m,k}\mu_m\mu_k+\sum_{m=i}^{i+\xi-1}b_{m,m}(\sigma^2+\mu_m^2)+\sum_{m=i}^{i+\xi-1}\alpha_{m}\Big(\sum_{k=i}^{i+\xi-1}b_{m,k}\Big)\\&~~~+
\sum_{m=i}^{i+\xi-1}\beta_{m}\Big(\sum_{l=i}^{i+\xi-1}b_{l,m}\Big)+
\sum_{m=i}^{i+\xi-1}\gamma_{m}\Big(\frac{1}{\tau}-b_{m,m}\Big)+\sum_{m=i}^{i+\xi-1}\delta_{m}b_{m,m}. 
\end{align*}
Thus, we obtain the following equations for solutions:  
$\bullet$ $\frac{\partial {\cal L}}{\partial b_{m,m}}= \sigma^2+\mu_m^2+\alpha_m+\beta_m-\gamma_{m}+\delta_m=0$, $\bullet$ $\frac{\partial {\cal L}}{\partial b_{m,k}}= 2\mu_m\mu_k+\alpha_m+\alpha_k+\beta_m+\beta_k=0,~m\neq k$, $\bullet$ $\frac{\partial {\cal L}}{\partial \alpha_{m}}=\sum_{k=i}^{i+\xi-1}b_{m,k}=0$, $\bullet$ $\frac{\partial {\cal L}}{\partial \beta_{m}}=\sum_{l=i}^{i+\xi-1}b_{l,m}=0$, $\bullet$ $\frac{\partial {\cal L}}{\partial \gamma_{m}}= \frac{1}{\tau}-b_{m,m}=0$, $\bullet$ $\frac{\partial {\cal L}}{\partial \delta_{m}}= b_{m,m}=0$, $\bullet$ $	\gamma_{m}\geq 0$, and $\bullet$ $\delta_{m}\geq 0$. Note that for $m\in \{i,i+1,\dots,i+\xi-1\}$, $\gamma_m$ and $\delta_m$ cannot be greater than $0$ at the same time since $\frac{\partial {\cal L}}{\partial \gamma_{m}}$ and $\frac{\partial {\cal L}}{\partial \delta_{m}}$ cannot be $0$ at the same time. 

Suppose that $\gamma_{m}=0$ and $\delta_m>0$ for $m\in \{i,i+1,\dots,i+\xi-1\}$. Then $\frac{\partial {\cal L}}{\partial b_{m,m}}=0$ implies that $\alpha_m+\beta_m=-\delta_m -\sigma^2-\mu_m^2$. Thus, $\frac{\partial {\cal L}}{\partial b_{m,k}}=0$ is equivalent to $(\mu_m-\mu_k)^2+2\sigma^2+\delta_m+\delta_k=0$, so it cannot be happen. 

On the other hand, if $\gamma_m>0$ and $\delta_m=0$ for $m\in \{i,i+1,\dots,i+\xi-1\}$,  then the conditions for solutions are $\bullet$ $(\mu_m-\mu_k)^2=\gamma_{m}+\gamma_{k},~m\neq k$,  $\bullet$ $b_{m,m}=\frac{1}{\tau}$, $\bullet$ $\sum_{k=i}^{i+\xi-1}b_{m,k}=0$, and $\bullet$ $\sum_{l=i}^{i+\xi-1}b_{l,m}=0$. Note that $b_{m,m}<\frac{1}{\tau}$ except $\tau=\xi$ because all elements in $\{a_{m+z_1\xi,m+z_1\xi}: z_1 \in Z_1\}$  are negative except $a_{m,m}$. Thus, the above optimal conditions are satisfied only when $\tau = \xi$, and in this cases, each $b_{m,k}$ is for $l,h=1,2,\dots,\xi-1$,  
\begin{eqnarray*}
& &b_{i,i}=a_{i,i}=\frac{1}{\xi},\\ 
& &b_{i+l,i+l}=a_{i+l,i+l}+a_{i+l-\xi,i+l}+a_{i+l,i+l-\xi}+a_{i+l-\xi,i+l-\xi}=\frac{1}{\xi},\\ 
& &b_{i,i+l}=a_{i,i+l}+a_{i,i+l-\xi}=-\frac{1}{\xi(\xi-1)},\\ 
& &b_{i+l,i}=a_{i+l,i}+a_{i+l-\xi,i}=-\frac{1}{\xi(\xi-1)},\\ 
& &b_{i+l,i+h}=a_{i+l,i+h}+a_{i+l-\xi,i+h}+a_{i+l,i+h-\xi}+a_{i+l-\xi,i+h-\xi}=-\frac{1}{\xi(\xi-1)}. 
\end{eqnarray*}

Finally suppose that there exists a nonempty set $A \subset \{i,i+1,\ldots,i+\xi-1\}$ such that $\gamma_m=0,~m\in A$ and  $\gamma_m>0,~m\in A^c$. It implies that $b_{m,m}=0,~m\in A$ and $b_{m,m}=\frac{1}{\tau},~m\in A^c$, which cannot be happen either. Therefore, for each $i$, $E[V_i^{{\bf X},\tau}]$ is uniquely maximized at $\tau=\xi$.
\end{proof}

\subsubsection*{A.2. Proof of Proposition~\ref{vi}}
\begin{proof} 
Note that $E(X_mX_k)=E\big[(X_m-\mu_m)(X_k-\mu_k)\big]+\mu_m\mu_k$, where $\mu_k:=E(X_k)$.  Since $\bf X$ is a periodically correlated process, it follows that 
$
E(X_mX_k)=E(X_{m+\xi}X_k)=E(X_mX_{k+\xi}).
$
Thus, from the expression of $E\left[{\bf V}^{{\bf X},\tau}\right]$ in A.1, it can be expressed as 
\[
E\left[{\bf V}^{{\bf X},\tau}\right]=\sum_{m,k=i-\tau+1}^{i+\tau-1}a_{m,k}E(X_mX_k)=\sum_{m,k=i}^{i+\xi-1}b_{m,k}E(X_mX_k),
\]
where the expression and conditions of $b_{m,k}$ are provided in A.1. Therefore, it can be proved by the procedure of Proposition~\ref{variancemax}. 
\end{proof}

\subsubsection*{A.3. Proof of Theorem~\ref{consist}}
\begin{proof}
For proof, we have modified the proof of Theorem 5.2.3 of Bickel and Doksum (2015). For fiexed $t$, let $D_0(\theta)=-E[V(t)]$. and $D_n(\theta)=-\bar{V}(t)$. Let 
\[
\theta_0=\argmin_{\theta \in {\cal C}} D_0(\theta)\quad\mbox{and}\quad \theta_n=\argmin_{\theta \in {\cal C}} D_n(\theta). 
\]
Suppose $|\theta_n-\theta_0|>\epsilon$. Put $\Delta_n=\sup_{\theta \in {\cal C}}|D_n(\theta)-D_0(\theta)|$. 
\newline
\textbf{Claim 1: } $\left| \inf_{|\theta-\theta_0|>\epsilon}D_0(\theta)-\inf_{|\theta-\theta_0|>\epsilon}D_n(\theta)  \right|  \leq \Delta_n$. 
\begin{proof}
Clearly, following equation holds for any $\theta \in \{\theta: |\theta - \theta_0|>\epsilon \}$
\begin{align*}
D_0(\theta) = \left( D_0(\theta) - D_n(\theta) \right) + D_n(\theta).
\end{align*}
Using the fact that $\sup (f+g) \leq \sup f +\sup g$ where $f,g$ are any realvalued functions, we can get 
\begin{align*}
\sup_{|\theta - \theta_0|>\epsilon} D_0(\theta) 
& \leq \sup_{|\theta - \theta_0|>\epsilon} \left( D_0(\theta) - D_n(\theta) \right) + \sup_{|\theta - \theta_0|>\epsilon}  D_n(\theta)  \\
& \leq \sup_{|\theta - \theta_0|>\epsilon} \left| D_0(\theta) - D_n(\theta) \right| + \sup_{|\theta - \theta_0|>\epsilon} D_n(\theta).
\end{align*}
Thus
\begin{align*}
\sup_{|\theta - \theta_0|>\epsilon} D_0(\theta)  - \sup_{|\theta - \theta_0|>\epsilon} D_n(\theta) 
\leq \sup_{|\theta - \theta_0|>\epsilon} \left| D_0(\theta) - D_n(\theta) \right|.
\end{align*}
A similar argument can be obtained below as well.
\begin{align*}
\underset{|\theta - \theta_0|>\epsilon}{\operatorname{sup}} D_n(\theta)  - \underset{|\theta - \theta_0|>\epsilon}{\operatorname{sup}}  D_0(\theta) 
\leq \underset{|\theta - \theta_0|>\epsilon}{\operatorname{sup}} \left| D_0(\theta) - D_n(\theta) \right|.
\end{align*}
Thus
\begin{align*}
\left | \underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}} D_n(\theta)  - \underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}}  D_0(\theta) \right| 
\leq \underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}} \left| D_0(\theta) - D_n(\theta) \right| 
\end{align*}
Substitute $-D_n(\theta)$ for $D_n(\theta)$ and substitute $-D_0(\theta)$ for $D_0(\theta)$ and using the facts that
\begin{align*}
\underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}} -D_n(\theta)= - \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}} D_n(\theta) \\ 
\underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}} -D_0(\theta)= - \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}} D_0(\theta)
\end{align*}
we get 
\begin{align*}
\left| \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}} D_n(\theta)  - \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}}  D_0(\theta) \right| 
\leq \underset{|\theta-\theta_0|>\epsilon}{\operatorname{sup}} \left| D_0(\theta) - D_n(\theta) \right|. 
\end{align*}
Thus 
\begin{align*}
\left| \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}} D_n(\theta)  - \underset{|\theta-\theta_0|>\epsilon}{\operatorname{inf}}  D_0(\theta) \right| \leq \Delta_n. 
\end{align*}
\end{proof}
We get from claim 1 that 
\begin{align*}
\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta) - \underset{|\theta-\theta_0|>\epsilon}{\inf} D_n(\theta)  
\leq 
\left|\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta) - \underset{|\theta-\theta_0|>\epsilon}{\inf} D_n(\theta) \right|
\leq \Delta_n,
\end{align*}
so 
\begin{align*}
\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta) \leq \underset{|\theta-\theta_0|>\epsilon}{\inf} D_n(\theta)+\Delta_n. 
\end{align*}
The condition $|\theta_n-\theta_0|>\epsilon$ 
implies 
$\underset{|\theta-\theta_0|>\epsilon}{\inf} D_n(\theta) \leq \underset{|\theta-\theta_0|\leq \epsilon}{\inf} D_n(\theta)$
thus 
\begin{align}
\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta) \leq \underset{|\theta-\theta_0|\leq \epsilon}{\inf} D_n(\theta)+\Delta_n.
\label{eq:thm32_1}
\end{align}
Using an argument similar to claim 1 we get 
\begin{align*}
\underset{|\theta-\theta_0|\leq\epsilon}{\inf}D_n(\theta) - \underset{|\theta-\theta_0|\leq\epsilon}{\inf} D_0(\theta)  
\leq 
\left|\underset{|\theta-\theta_0|\leq \epsilon}{\inf}D_0(\theta) - \underset{|\theta-\theta_0|\leq \epsilon}{\inf} D_n(\theta) \right|
\leq \Delta_n,
\end{align*}
so 
\begin{align}
\underset{|\theta-\theta_0|\leq \epsilon}{\inf}D_n(\theta) \leq \underset{|\theta-\theta_0|\leq\epsilon}{\inf} D_0(\theta)+\Delta_n. 
\label{eq:thm32_2}
\end{align}
From (\ref{eq:thm32_1}) and (\ref{eq:thm32_2}), we have
\begin{align*}
\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta) \leq \underset{|\theta-\theta_0|\leq \epsilon}{\inf} D_n(\theta)+\Delta_n \leq \underset{|\theta-\theta_0|\leq\epsilon}{\inf} D_0(\theta)+2\Delta_n=D_0(\theta_0)+2\Delta_n. 
\end{align*}
Let $\delta(\epsilon):= \frac{1}{2}\Big[\underset{|\theta-\theta_0|>\epsilon}{\inf}D_0(\theta)-D_0(\theta_0)\Big]$ then 
$\Delta_n \geq \delta(\epsilon)$. Thus 
\begin{align*}
P\left(\left|\theta_n-\theta_0\right|>\epsilon\right) \leq P\left(\Delta_n\leq \delta(\epsilon)\right).
\end{align*}
Since $\Delta_n \overset{p}{\rightarrow} 0$, the proof is done when $\delta(\epsilon)>0$. It is left in claim 2 to prove that $\delta(\epsilon)$ is positive.
\end{proof} 
\noindent\textbf{Claim 2: } $\delta(\epsilon)>0$. 
\begin{proof}
dd
\end{proof}

\subsubsection*{A.4. Proof of Lemma~\ref{lem1}}
\begin{proof}
From Definition 2 that defines elastic-bands by cubic spline function, there exists $\ell^*\in \{1,2,\dots,\xi\}$ such that 
\[
X_{i,\ell}^{\xi}=X_{i+\ell^*-\xi}+b_{i+\ell^*-\xi}(\xi-\ell^*)+c_{i+\ell^*-\xi}(\xi-\ell^*)^2+d_{i+\ell^*-\xi}(\xi-\ell^*)^3
\]
for each $\ell$ and $i$ (de Boor, 1978). Here $b_{i+\ell^*-\xi}$, $c_{i+\ell^*-\xi}$ and $d_{i+\ell^*-\xi}$ are obtained by solving the following equations: 
(i) $X_{i+\ell^*}=X_{i+\ell^*-\xi}+\xi b_{i+\ell^*-\xi}+\xi^2c_{i+\ell^*-\xi}+\xi^3d_{i+\ell^*-\xi}$, 
(ii) $b_{i+\ell^*}=b_{i+\ell^*-\xi}+2\xi c_{i+\ell^*-\xi}+3\xi^2d_{i+\ell^*-\xi}$, and 
(iii) $2c_{i+\ell^*}=2c_{i+\ell^*-\xi}+6\xi d_{i+\ell^*-\xi}$. 
Then $Z$-transforms of the above three equations are 
\begin{eqnarray}
\label{eq:Z-transform}
X(z)z^{\ell^*}&=&X(z)z^{\ell^*-\xi}+\xi b(z)z^{\ell^*-\xi}+\xi^2c(z)z^{\ell^*-\xi}+\xi^3d(z)z^{\ell^*-\xi}\nonumber\\
b(z)z^{\ell^*}&=&b(z)z^{\ell^*-\xi}+2\xi c(z)z^{\ell^*-\xi}+3\xi^2d(z)z^{\ell^*-\xi}\nonumber\\
2c(z)z^{\ell^*}&=&2c(z)z^{\ell^*-\xi}+6\xi d(z)z^{\ell^*-\xi}.\nonumber 
\end{eqnarray}
So, the solutions of the above equations are $b(z)= \frac{-3z^{-\xi}+3z^{-\xi}}{\xi(z^{\xi}+4+z^{-\xi})}X(z)$, 
$c(z)= \frac{3z^{-\xi}-6+3z^{\xi}}{\xi^2(z^{\xi}+4+z^{-\xi})}X(z)$, and 
$d(z)= \frac{-z^{-\xi}+3-3z^{\xi}+z^{2\xi}}{\xi^3(z^{\xi}+4+z^{-\xi})}X(z)$.  Thus, $Z$-transform of $X_{i,\ell}^{\tau}$ is 
\begin{align*}
{\cal Z}\{X_{i,\ell}^{\xi}\}=&X(z)z^{\ell^*-\xi}+b(z)z^{\ell^*-\xi}(\xi-\ell^*)+c(z)z^{\ell^*-\xi}(\xi-\ell^*)^2+d(z)z^{\ell^*-\xi}(\xi-\ell^*)^3\\
=&\left[z^{\ell^*-\xi}+H_b(z)(\xi-\ell^*)z^{\ell^*-\xi}+H_c(z)(\xi-\ell^*)^2z^{\ell^*-\xi}+H_d(z)(\xi-\ell^*)^3z^{\ell^*-\xi} \right]X(z), 
\end{align*}
where $H_b(z)=\frac{3\xi^2(z^{\xi}+1)(z^{\xi}-1)}{\xi^3(z^{2\xi}+4z^{\xi}+1)}$, $H_c(z)=\frac{3\xi(z^{\xi}-1)^2}{\xi^3(z^{2\xi}+4z^{\xi}+1)}$ and $H_c(z)=\frac{(z^{\xi}-1)^3}{\xi^3(z^{2\xi}+4z^{\xi}+1)}$. Hence,  $Z$-transform of $M_{i}^{\xi}\{X_i\}$ can be expressed as 
$
{\cal Z}\{M_i^{\xi}\{X_i\}\}=H_{\xi}(z)X(z), 
$
where 
\begin{align*}\label{eq:Hz}
H_{\xi}(z)=&\frac{1}{\xi}\sum_{\ell^*=1}^{\xi}z^{\ell^*-\xi}+\frac{H_b(z)}{\xi}\sum_{\ell^*=1}^{\xi}(\xi-\ell^*)z^{\ell^*-\xi}+\frac{H_c(z)}{\xi}\sum_{\ell^*=1}^{\xi}(\xi-\ell^*)^2z^{\ell^*-\xi} \\
&+\frac{H_d(z)}{\xi}\sum_{\ell^*=1}^{\xi}(\xi-\ell^*)^3z^{\ell^*-\xi}. 
\end{align*}
Suppose that $z=e^{\frac{2\pi m j}{\xi}}$ for $m=1,\dots,\xi-1$. Then $H_b(z)=H_c(z)=H_d(z)=0$ and 
\begin{align*}
\frac{1}{\xi}\sum_{\ell^*=1}^{\xi}z^{\ell^*-\xi}&=\frac{z^{-\xi+1}(1-z^{\xi})}{\xi(1-z)}=\frac{z^{-\xi+1}}{\xi(z-1)}\prod_{m=0}^{\xi-1}\left(z-e^{\frac{2\pi m j}{\xi}}\right)\\
&=\frac{z^{-\xi+1}}{\xi}\prod_{m=1}^{\xi-1}\left(z-e^{\frac{2\pi m j}{\xi}}\right)=0.
\end{align*}
Therefore, $H_{\xi}(z)=0$ at $z=e^{\frac{2\pi m j}{\xi}}$ for $m=1,\dots,\xi-1$ and $H_{\xi}(\omega)=0$ for $\omega \in \big\{\omega:\omega=\frac{2\pi k}{\xi}\pm 2n\pi,~\textup{for } \ell=1,\dots,\xi~\textup{and } n\in \mathbb{N}\big\}$.
\end{proof}

\subsubsection*{A.5. Proof of Lemma~\ref{lem2}}
\begin{proof}
Define the cubic B-spline function $B(t)$ as
\[
B(t)=\begin{cases}
\frac{2}{3}-t^2\left(1-\frac{1}{2}|t|\right), & |t|\leq 1 \\ 
\frac{1}{6}(2-|t|)^3,& 1<|t|<2 \\ 
0,&\mbox{otherwise}. 
\end{cases}
\]
Cubic spline function can be expressed as a linear combination of B-splines. Thus, the sum of $\xi$ cubic spline functions is 
\begin{align*}
\sum_{\ell=1}^{\xi}S_{\ell}^{\xi}(t)=&\sum_{\ell=1}^{\xi}\sum_{k=-\infty}^{\infty}6B_{\ell+k\xi}(t)w_{\ell+k\xi}=\sum_{\ell=1}^{\xi}\sum_{k=-\infty}^{\infty}6B\Big(k-\frac{t-\ell T}{\xi T}\Big)w_{\ell+k\xi}\\
=&\sum_{\ell=1}^{\xi}6(B\ast w)\Big(\frac{t-\ell T}{\xi T}\Big)
=6(B\ast w)\Big(\frac{t}{\xi T}\Big) \ast \sum_{\ell=1}^{\xi} \delta\Big(t-\ell T\Big), 
\end{align*}
where $w(t)=\sum_{k=-\infty}^{\infty}w_{\ell+k\xi}\delta(t-k)$. Here $w_i$ denotes an inverse $Z$-transform of $W(z)=\frac{X(z)}{z+4+z^{-1}}$, and $W(z)$ is derived by Aldroubi et al. (1992). Note that $B(t)=\phi(t)^{*4}$, where $\phi(x)=1$ for $|t|\leq 1/2$ and $\phi(x)=0$ for otherwise, and $x^{*k}=\underset{k}{\underbrace{x*x*\dots*x}}$ denotes convolution power. Fourier transform of $B\left(\frac{t}{\xi T}\right)$ is given by 
\[
{\cal F}\Big\{B\Big(\frac{t}{\xi T}\Big)\Big\}={\cal F}\Big\{\phi\Big(\frac{t}{\xi T}\Big)\Big\}^4 \geq 0
\]
since $\phi\big(\frac{t}{\xi T}\big)$ is symmetric. The term $w\big(\frac{t}{\xi T}\big) \ast \sum_{\ell=1}^{\xi}\delta\big(\frac{t-\ell T}{\xi T}\big)$ can be expressed as $w_{\delta}(t)=\sum_{i=-\infty}^{\infty} w_i\delta(t-iT)$ that is continuous-time representation of discrete-time signal $w_i$. Fourier transform of $w_{\delta}(t)$ is 
\[
{\cal F}\{w_{\delta}(t)\}=\frac{X_{\delta}(\omega)}{e^{j\omega\xi}+4+e^{-j\omega\xi}}, 
\]
where $X_{\delta}(\omega)$ denotes Fourier transform of $X_{\delta}(t)=\sum_{i=-\infty}^{\infty} X_i\delta(t-iT)$. Note that $e^{j\omega\xi}+4+e^{-j\omega\xi}=\left(e^{j\omega\xi/2}+e^{-j\omega\xi/2}\right)^2+2>0$.
Thus, Fourier transform of $M_{i}^{\xi}(\{\delta_i\})$ is real and positive. Since $H_{\xi}(\omega)$ is maximized at $\omega=0$ and the maximum value is 1, by Lemma~\ref{lem1}, it follows that
$
0<H_{\xi}(\omega)\leq 1
$ 
except for $\omega \in \big\{\omega:\omega=\frac{2\pi k}{\xi}\pm 2n\pi,~\textup{for } k=1,\dots,\xi~\textup{and } n\in \mathbb{N}\big\}$. 
\end{proof}


\subsubsection*{A.6. Proof of Corollary~\ref{cor1}}
\begin{proof}
Note that for each $\ell$ and $i$, there exist $\ell^*\in \{1,2,\dots,\xi\}$ such that 
\[
X_{i,\ell}^{\xi}=\frac{\ell^*X_{i+\ell^*-\xi}+(\xi-\ell^*)X_{i+\ell^*}}{\xi},
\]
thus Z-transform of $X_{i,\ell}^{\xi}$ is 
\[
{\cal Z}\{X_{i,\ell^*}^{\xi}\}=\frac{\ell^*}{\xi}X(z)z^{\ell^*-\xi}+\frac{\xi-\ell^*}{\xi}X(z)z^{\ell^*}.
\]
Thus 
\[
{\cal Z}\{M_{i}^{\xi}\}=\frac{1}{\xi}\left[\sum_{\ell^*=1}^{\xi}z^{\ell^*}+\frac{z^{-\xi}-1}{\xi}\sum_{\ell^*=1}^{\xi}\ell^* z^{\ell^*}\right]X(z)
=\frac{1}{\xi}\left[ S_1+ \frac{z^{-\xi}-1}{\xi}S_2 \right]X(z)
\]
where $S_1=\sum_{\ell^*=1}^{\xi}z^{\ell^*}$ and $S_2=\sum_{\ell^*=1}^{\xi}\ell^* z^{\ell^*}$. Using the fact that 
$S_2=\frac{S_1 -\xi z^{\xi+1}}{1-z}$ then
\begin{align*}
S_1+\frac{z^{-\xi}-1}{\xi}S_2=&S_1+\frac{z^{-\xi}-1}{\xi}\frac{S_1 -\xi z^{\xi+1}}{1-z}=S_1+S_1\frac{-(1-z^{-\xi})}{\xi(1-z)}-S_1
=S_1^2\frac{1}{\xi z^{\xi+1}}
\end{align*}
Thus the transfer function $H_{\xi}(z)$ can be defined by 
$H_{\xi}(z)=\left(\frac{S_1z^{\frac{-\xi-1}{2}}}{\xi}\right)^2$. To consider the Fourier response, set $z=e^{j\omega}$. 
Note that $\left(\frac{S_1z^{\frac{-\xi-1}{2}}}{\xi}\right)$ is real since 
$
\left(\frac{z(z^{\xi}-1)}{\xi(z-1)}\right) z^{\frac{-\xi-1}{2}}=\left(\frac{z^{-1}(z^{-\xi}+1)}{\xi(z^{-1}-1)}\right) z^{\frac{\xi+1}{2}}
$
thus $H_{\xi}(z)$ is real and positive. 
Now observe that  $H_{\xi}(z)=|H_{\xi}(z)|=\left|S_1^2\right|\frac{1}{\xi^2}\leq 1$. Thus 
\[
0\leq 1-H_{\xi}(z) \leq 1. 
\]
Since $S_1=\frac{z(1-z^{\xi})}{1-z}=\frac{z}{z-1}\prod_{m=0}^{\xi-1}\left(z-e^{\frac{2\pi m j}{\xi}}\right)=z\prod_{m=1}^{\xi-1}\left(z-e^{\frac{2\pi m j}{\xi}}\right)
$, $S_1=0$ when $z=e^{\frac{2\pi m j}{\xi}}$ for all $m=1,\dots,\xi-1$. Thus 
\[
0\leq 1-H_{\xi}(\omega) < 1
\]
except for $\omega \in \big\{\omega: \omega=\frac{2\pi k}{\xi}, \textup{~for all } k=1,\dots,\xi~\textup{and } n\in \mathbb{N}\big\}$. 
\end{proof}

