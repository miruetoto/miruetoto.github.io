---	
layout: post	
title: (정리) 주성분분석	
--- 	

### About this doc

- 여기에서는 주성분분석에 대하여 다룬다. 

- 처음에는 차원축소적인 개념으로 설명한다. 

### 차원축소

- 차원축소란 입력차원 $\\{ {\bf x}_ i\\}_ {i=1}^{n}$의 차원이 매우 클때 그것을 낮은차원의 자료들 $\\{ {\bf z}_ i\\}_ {i=1}^{n}$로 바꾸는 방법을 말한다. 	
- 차원축소를 수행하는 연산이 선형이면 적당한 행렬 ${\bf T}$를 사용하여 ${\bf z}_ i={\bf x}_ i{\bf T}$와 같은 방식으로 쓸 수 있다. 가령 예를 들어서 ${\bf x}_ i=[1,2,4,5,8]$과 같은 자료가 있다고 하자. 이때 ${\bf x}_ i$의 차원은 $1\times 5$이다. 그러면 ${\bf T}$를 $5\times 2$와 같은 행렬을 잡아와서 ${\bf z}_ i={\bf x}_ i{\bf T}$와 같이 쓸 수 있는데 이러면 ${\bf z}_ i$의 차원은 $1 \times 2$가 되고 ${\bf T}$는 5차원자료를 2차원으로 줄이는 변환이 된다. 좀 더 일반적으로는 아래와 같이 선형변환을 표현할 수 있다. 	
\begin{align}	
{\bf Z}_ {n\times p'} = {\bf X}_ {n \times p} {\bf T}_ {p \times p'} 	
\end{align}	

### 주성분분석 

- 주성분 분석은 (1) ${\bf z}_ i$가 ${\bf x}_ i$의 정사영이라는 제약아래에서 (2) ${\bf z}_ i \approx {\bf x}_ i$가 최대한 만족하도록 하는 선형변환 ${\bf T}$를 찾고자 하는 기법이다. 여기에서 (1)은  ${\bf T}'{\bf T}={\bf I}_ {p' \times p'}$이라는 조건과 동치이다(이게 이해안되면 선대다시공부해야함). 	

- (2)를 만족하기 위해서는 $\sum_{i=1}^{n} \\| {\bf z}_ i - {\bf x}_ i \\|^2$을 최소화 하면 될것이다. 그런데 ${\bf z}_ i$와 ${\bf x}_ i$의 차원이 다르므로 직접거리를 잴 수 없다. 따라서 ${\bf z}_ i$에 ${\bf T'}$를 곱한 아래식을 최소화 한다. 	
\begin{align}	
\sum_{i=1}^{n} \\|{\bf z}_ i {\bf T'}-{\bf x}_ i \\|^2= \sum_ {i=1}^{n}  \\| {\bf x}_ i {\bf T} {\bf T'} - {\bf x}_ i \\|^2 	
\end{align}	
고정된 $i$에 대하여 $\\| {\bf x}_ i {\bf T} {\bf T'} - {\bf x}_ i \\|^2 $을 풀면 ${\bf x}_ i{\bf x}_ i' -{\bf x}_ i {\bf T}{\bf T'} {\bf x}_ i'$가 되어서 위의식은 아래와 같이 정리된다. 	
\begin{align}	
\sum_{i=1}^{n}  \\| {\bf x}_ i {\bf T} {\bf T'} - {\bf x}_ i \\|^2 = -tr({\bf T'}{\bf X'}{\bf X}{\bf T})+tr({\bf X'}{\bf X})	
\end{align}	
잠깐 세부계산을 살펴보자. <br/><br/>	
1) $\\| {\bf x}_ i {\bf T} {\bf T'} - {\bf x}_ i \\|^2 $을 풀면 ${\bf x}_ i{\bf x}_ i' -{\bf x}_ i {\bf T}{\bf T'} {\bf x}_ i'$가 되는것은 ${\bf a}$가 row-vector일때 $\\|{\bf a}\\|^2={\bf a}{\bf a}'$임을 이용하면 쉽게 구할 수 있다. <br/><br/>	
2) $\sum_{i=1}^{n}{\bf x}_ i {\bf x}_ i'=tr({\bf X}{\bf X}')=tr({\bf X}'{\bf X})$가 된다. 여기에서 두번째 등호가 성립하는 이유는 $tr({\bf A}{\bf B})=tr({\bf B}{\bf A})$이기 때문이다. <br/><br/>	
3) 혹은 매트릭스쿡북 p6-(17) 공식 ${\bf a}'{\bf a}=tr({\bf a}{\bf a}')$를 이용하여 2)의 수식을 계산할 수도 있다. 	
매트릭스쿡북의 공식은 col-vector일때를 기준으로 쓴 것이므로 row-vector인 ${\bf x}_ i$의 경우는 $ {\bf x}_ i {\bf x}_ i'=tr({\bf x}_ i' {\bf x}_ i)$와 같이 적용할 수 있다. 따라서 	
$\sum_{i=1}^{n} {\bf x}_ i {\bf x}_ i' =\sum_{i=1}^{n}tr({\bf x}_ i' {\bf x}_ i)=tr(\sum_{i=1}^{n}{\bf x}_ i' {\bf x}_ i)=tr({\bf X}'{\bf X})$	
와 같이 된다.  <br/><br/>	
4) 위에서 언급한 ${\bf a}'{\bf a}=tr({\bf a}{\bf a}')$를 다시 이용하면 ${\bf x}_ i {\bf T}{\bf T'} {\bf x}_ i'=tr({\bf T'} {\bf x}_ i'{\bf x}_ i {\bf T})$가 된다. 따라서 	
$\sum_i^{n}{\bf x}_ i {\bf T}{\bf T'} {\bf x}_ i'=tr({\bf T}'\sum_i^n {\bf x}_ i'{\bf x}_ i  {\bf T})=tr({\bf T}'{\bf X}'{\bf X}{\bf T})$	
가 된다. <br/><br/>	

- 세부 계산때문에 다소 난잡해졌지만 PCA는 결국 ${\bf T}'{\bf T}={\bf I}$라는 제약조건하에서 아래식을 최소화하는 ${\bf T}$를 찾으면 된다. 	
\begin{align}	
-tr({\bf T'}{\bf X'}{\bf X}{\bf T})+tr({\bf X'}{\bf X})	
\end{align}	
여기에서 ${\bf X}$는 *given*되어 있으므로 ${\bf T}$에 대한 상수이다. 라그랑주 승수법을 사용하면 결국 PCA는 아래식을 최대화하는 $({\bf T},{\bf K})$를 찾으면 된다. 	
\begin{align}	
tr({\bf T'}{\bf X'}{\bf X}{\bf T})+ {\bf K} \left({\bf I}-{\bf T}'{\bf T}\right)	
\end{align}	
여기에서 ${\bf K}= diag(k_1,\dots, k_p)$ 이고 $k_1,\dots,k_p$ 는 라그랑주 상수이다. 원래 라그랑주 상수는 $\lambda$로 주로 표시하지만 이는 후에 나오는 고유치와 기호가 겹쳐서 여기서는 부득이하게 $k$로 정의하였다. 아무튼 ${\bf T}$로 미분하면 아래와 같이 된다. 	
\begin{align}	
2{\bf X}'{\bf X}{\bf T}- 2{\bf T}{\bf \Lambda}	
\end{align}	
또한 ${\bf K}$로 미분하면 ${\bf T}'{\bf T}={\bf I}$가 된다. 두 식을 연립하면 아래와 같이 된다. 	
\begin{align}	
\begin{cases}	
{\bf X}'{\bf X}{\bf T}={\bf T}{\bf K} \\\\ 
{\bf T}'{\bf T}={\bf I}	
\end{cases}	
\end{align}	
즉 이걸 풀면 된다. 	

- 푼 결과만 말하면 식	
\begin{align}	
\begin{cases}	
{\bf X}'{\bf X}{\bf T}={\bf T}{\bf K} \\\\ 
{\bf T}'{\bf T}={\bf I}	
\end{cases}	
\end{align}	
을 만족하는 해 $({\bf T},{\bf K})$ 는 아래와 같다. 
\begin{align}	
\begin{cases}	
{\bf T}_ {p \times p'}=[T_1,\dots,T_ {p'}]=[{\boldsymbol \psi}_ 1, \dots,{\boldsymbol \psi}_ {p'}]={\bf \bar\Psi}_ {p\times p'}	 \\\\ \\
{\bf K}_ {p' \times p'}=diag(k_ 1 , \dots , k_ {p'})=diag(\lambda_ 1 , \dots , \lambda_ {p'})={\bf \bar\Lambda}_ {p' \times p'}
\end{cases}	
\end{align}	
이다. 여기에서 ${\bf \Psi},{\bf \Lambda}$ 는 각각 ${\bf X}{\bf X}'$ 의 고유벡터와 고유치이며 ${\bf \bar\Psi}_ {p \times p'}$ 와 ${\bf \bar\Lambda}_ {p' \times p'}$ 는 각각 ${\bf \Psi}_ {p\times p}$ 와 ${\bf \Lambda}_ {p\times p}$ 의 짤린버전이다. 즉 ${\bf T}_ {p\times p'}$는 ${\bf X}'{\bf X}$의 고유벡터에서 **뒷부분에 위치한 덜 중요해보이는 $(p-p')$개의 고유벡터를 삭제한 것**과 같고, ${\bf K}_ {p'\times p'}$는 ${\bf X}'{\bf X}$의 고유치에서 **뒷 부분에 위치한 덜 중요해보이는 $(p-p')$개의 고유치를 삭제한것**과 같다. 

- 위의 결론을 증명하는 것은 어렵지 않다. 그냥 ${\bf X}'{\bf X}{\bf T}={\bf T}{\bf K}$ 에다가 ${\bf T}_ {p \times p'}=[{\boldsymbol \psi}_ 1, \dots, {\boldsymbol \psi}_ {p'}]$를 대입하면 쉽게 할 수 있다. (식 ${\bf T}'{\bf T}={\bf I}$는 고유벡터의 정의에 의해서 그냥 성립하므로 체크할 필요도 없다.) 	
\begin{align}	
{\bf X}'{\bf X}{\bf T}&
={\bf X}'{\bf X}[T_1, \dots, T_ {k'}] \\\\ \\
&={\bf X}'{\bf X}[{\boldsymbol \psi}_ 1, \dots, {\boldsymbol \psi}_ {p'}] \\\\ 
&=[{\bf X}'{\bf X}{\boldsymbol \psi}_ 1, \dots, {\bf X}'{\bf X}{\boldsymbol \psi}_ {p'}] \\\\ \\
&= [\lambda_ 1{\boldsymbol \psi}_ 1 , \dots, \lambda_{p'}{\boldsymbol \psi}_ {p'}] \\\\ \\
&=[{\boldsymbol \psi}_ 1, \dots, {\boldsymbol \psi}_ {p'}]diag(\lambda_1,\dots,\lambda_{p'}) \\\\ \\
&=[T_1,\dots,T_ {p'}]diag(k_1,\dots,k_ {p'})={\bf T} {\bf K}
\end{align}

### 자유로운 식 변환, 용어정리. 

- 아래식들에서 시작하자. 
\begin{align}
\bf X=UDV'
\end{align}
\begin{align}
\bf X'X=\Psi\Lambda\Psi'
\end{align}
\begin{align}
\bf Z=XT=X\bar\Psi
\end{align}

- SVD는 아래와 같이 정의하는 것이 편리하다. 
\begin{align}
{\bf X}_ {n\times p}={\bf U}_ {n\times n} {\bf D}_ {n \times p} {\bf V}_ {p\times p}'
\end{align}
따라서 ${\bf D}$는 대각행렬이 아니다. 

- 아래가 성립한다. 
\begin{align}
\bf X'X = V D'U' U D V' = \Psi \Lambda \Psi'
\end{align}
따라서 아래와 같이 정의하는 것이 좋다. 
\begin{align}
\bf V:&= \bf \Psi \\\\ \\
\bf U'U:&= \bf I \\\\ \\
\bf D'D:&= \bf \Lambda 
\end{align}

- ${\bf V}$, ${\bf \Psi}$ 를 right-eigenvector of $\bf X'X$ 라고 부른다. (통상적으로 우리가 정의했던 고유벡터는 모두 right-eigen vector이다) 왜냐하면 아래식이 성립하기 때문이다. 
\begin{align}
\bf X'X V = V \Lambda
\end{align}
\begin{align}
\bf X'X \Psi = \Psi \Lambda
\end{align}

- 아래식이 성립한다. 
\begin{align}
\bf XX'=UDV'VD'U'=U(DV'VD')U'=U\Gamma U'
\end{align}
여기에서 가운데 $\bf \Gamma=DV'VD'$는 새로운 대각행렬로 볼 수 있다. 아래식이 성립한다. 
\begin{align}
\bf U'XX'=\Gamma U'
\end{align}
이때 $\{U_1,\dots,U_n\}$ 을 $\bf XX'$ 의 left-eigen vector 라고 하며 $\gamma_1,\dots,\gamma_n$을 그에 대응하는 고유치라고 하자. 

- 우고유벡터는 col형태로 오른쪽에 곱하며 좌고유벡터는 row형태로 왼쪽에 곱한다. 모양은 대충 아래와 같은 느낌이다. 
\begin{align}
\begin{bmatrix}
\blacksquare  & \blacksquare  & \dots & \blacksquare \\
\blacksquare  & \blacksquare  & \dots & \blacksquare \\ 
\dots & \dots & \dots &\dots \\ 
\blacksquare  & \blacksquare  & \dots & \blacksquare 
\end{bmatrix}
\begin{bmatrix}
\bullet \\ 
\bullet \\ 
\dots \\ 
\bullet
\end{bmatrix}=\lambda \begin{bmatrix}
\bullet \\ 
\bullet \\ 
\dots \\ 
\bullet
\end{bmatrix}
\end{align}

- 아래를 주의하자. 
\begin{align}
{\bf T T'=I} \quad \mbox{but} \quad {\bf T'T\neq I}
\end{align}

\begin{align}
{\bf \Psi \Psi'=I} \quad \mbox{but} \quad {\bf \Psi'\Psi\neq I}
\end{align}

- 

