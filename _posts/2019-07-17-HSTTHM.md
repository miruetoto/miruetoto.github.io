---
title : (논문) Theory of HST 
layout: post 
---

### About this doc

- 이 문서에서는 HST에 대한 몇 가지 이론적 성질들을 struct 한다. 

### HST 

- 그래프형태의 자료에 $(V,E,f(V))$에서의 hst를 $(V,E,\boldsymbol{h}(V))$라고 정의하자. 각각의 $i=1,\dots,n$에 대하여 $\boldsymbol{h}(v_i)$ 는 크기가 $(\tau+1) \times 1$인 벡터이다. 각각의 $i,j \in \\{1,\dots,n\\}$ 에 대하여 노드 $v_i$, $v_j$ 간의 snow-dist는 아래와 같이 정의한다. 
\begin{align}
sdist(v_i,v_j) := \\|\boldsymbol{h}(v_i)-\boldsymbol{h}(v_j) \\|_ 2^2 
\end{align}
각각의 노드에 새롭게 쌓인 눈의 양만을 알고 싶다면 아래를 살펴보는 것도 좋다. 
\begin{align}
\boldsymbol{\dot h}(v_1), \dots, \boldsymbol{\dot h}(v_n).
\end{align}
이것은 각각 $\boldsymbol{h}(v_1),\dots,\boldsymbol{h}(v_n)$ 을 차분해서 얻을 수 있는 길이가 $\tau \times 1$ 벡터이다. 

- 각 노드에 내리는 눈의 양을 $\epsilon(v_i)$ 라고 하자. ${\cal N}(i,\ell)$ 를 아래와 같이 정의하자. 
\begin{align}
{\cal N}(i,\ell) := \\{j:(i,j)\in E , ~ h^{\ell}(v_i) \leq h^{\ell}(v_j) \\} 
\end{align}
그러면 각 노드에 쌓인 눈의 양을 아래와 같이 정의할 수 있다. 
\begin{align}
h^{\ell}(v_i)=\sum_{j \in {\cal N}(i,\ell-1)}\Big( \frac{1}{\|{\cal N}(j) \| }\epsilon(v_j)+\frac{1}{\|{\cal N}(i) \| }\epsilon(v_i)\Big) + h^{\ell-1}(v_i) 
\end{align}
매트릭스를 이용하여 정의하여 보자. 신호 $f(V)$를 길이가 $n$인 벡터라고 하고 매트릭스 ${\bf A}^{(\ell)}$ 을 $n\times n$ 매트릭스라고 하자. 노드 $v_i$ 에서 노드 $v_j$로 눈이 이동할 수 있으면 ${\bf A}^{(\ell)}$의 $(i,j)$의 원소를 1이라고 하자. 아닌 경우는 0이라고 가정하자. 아래와 같이 쓸 수 있다. 
\begin{align}
\Big({\bf A}^{(\ell)}\Big)_ {ij}=a_{ij}^{\ell}=\begin{cases} 1 & h^{\ell}(v_i)>h^{\ell}(v_j) \\\\ 0 & o.w. \end{cases}
\end{align}
이제 아래와 같이 쓸 수 있다. 
\begin{align}
{\boldsymbol h}^{\ell}= \Big[ \frac{1}{sumof}{\bf A}^{(\ell)}+ \frac{1}{sumof} \big({\bf A}^{(\ell)}\big)' \Big] {\boldsymbol \epsilon}+ {\boldsymbol h}^{\ell-1} 
\end{align}


- 만약에 자료 $G=(V,E)$가 시계열을 의미하고 각각의 확률변수가 
\begin{align}
f(v_1),\dots f(v_n) ~ \sim ~ i.i.d. ~ F
\end{align}
라고 하자. 그러면 $v_i$에 대응하는 확률벡터 $\boldsymbol{\dot h}(V)$는 역시 서로 독립이고 같은 분포를 가진다. 즉  
\begin{align}
\boldsymbol{\dot h}(v_1),\dots \boldsymbol{\dot h}(v_n) ~ \sim ~ i.i.d. ~ \tilde F
\end{align}
이다. (당연한것 같긴한데 그래도 증명이 필요하긴 할듯) 

- $T$를 분포 $\tilde F$에서 $\mathbb{R}$ 로 가는 functional 이라고 하자. 여기에서
\begin{align}
T(\tilde F_n)=\sum_{(i,j) \in E} \\| \boldsymbol{\dot h}(v_i)-\boldsymbol{\dot h}(v_j) \\|_ 2^2
\end{align}
에 대응하는 $T(F)$ 는 무엇일까?

- **(햄팰 p.417)** ${\boldsymbol X}$를 ***timeseries*** 라고 하자. 즉 ${\boldsymbol X}$는 $(\Omega,{\cal F})$ 에서 $(\mathbb{R}^{\mathbb{N}},{\cal R}^{\mathbb{N}})$으로 가는 메저러블맵핑이다. 타임시리즈 ${\boldsymbol X}$ 에서 sample 한 finite sample $(X_1,\dots,X_n)$ 을 관찰하였다고 하자. 타임시리즈 ${\boldsymbol X}$의 cdf 를 $F$라고 하자. 그리고 확률벡터 $(X_1,\dots,X_n)$의 cdf 를 $F_n$ 이라고 하자. 여기에서 $F$가 ***stationary ergodic distribution*** 이라면 적당한 mild regularity condition 하에서 $T_n$이 $T(F^{(m)})$로 수렴한다. 여기에서 $F^{(m)}$ 은 차원이 $m$ 인 $F$ 의 마지날이다. $T$는 $m$ 차원 프로덕트 스페이스에서 정의되는 probability measure 처럼 행동한다. 즉 
\begin{align}
\int \psi(x_m,\dots,x_1 ; T(G)) dG(x_1,\dots,x_m)=0
\end{align}
이다. 이때 $G$는 $T$의 도메인에서 정의되는 임의의 함수이다. 이제 IF를 정의하여 보자. ***i.i.d.*** case 와 유사하게 아래와 같이 정의할 수 있다.
\begin{align}
IF(x_m,\dots,x_1; T, F^{(m)})=
\lim_{h\downarrow 0} \frac{T((1-h)F^{(m)}+h\Delta_{(x_1,\dots,x_m)}-T(F^{(m)})}{h}
\end{align}


- $\tilde F_n$을 벡터 $\boldsymbol{\dot h}(v_1),\dots,\boldsymbol{\dot h}(v_n)$에 대응하는 empirical-cdf 라고 하자. 글리벤코-칸텔리 정리에 의해서 $\tilde F_n \to \tilde F$ 가 성립한다. 따라서 적당히 큰 $n$에 대하여 $\tilde F_n$은 $F$의 neighborhood에 속한다고 볼 수 있다. 따라서 
\begin{align}
T(\tilde F_n) & \approx  T( \tilde F)+\int IF(x,T, \tilde F)d(\tilde F_n-\tilde F)(x) \\\\ \\ 
& = T(\tilde F)+\int IF(x,T,\tilde F) d\tilde F_n(x) 
\end{align}
이다. 여기에서 $\int IF(x,T,\tilde F)d\tilde F(x)=0$ 임이 사용되었다. 따라서 
\begin{align}
\sqrt{n}\Big(T(\tilde F_n)-T(\tilde F) \Big) \to N(0,V(T,F))
\end{align}
이다. 여기에서 $V(T,\tilde F)=\int IF(x,T,\tilde F)^2 d\tilde F(x)$ 이다. 
