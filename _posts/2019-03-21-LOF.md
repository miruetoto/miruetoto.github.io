---
layout: post 
title: (리뷰) LOF
---

### About this document 
- 여기서는 아래의 논문을 요약하였다. <br/>
***REF***: Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May). LOF: identifying density-based local outliers. In ACM sigmod record (Vol. 29, No. 2, pp. 93-104). ACM.

- 위의 논문에서는 **리처빌리티-디스턴스*(Reachability Distance)*** 라는 개념이 나오는데 이것이 HST에서 제안하는 dissimilarity와 유사하다. 이 논문에서 제시한 anormally detection방법과 우리의 방법을 비교해보면 매우 유익할것이다. 

- 가급적 논문에 나오는 노테이션을 따라갈것이다. 하지만 도저히 못따라가겠는 노테이션이 있는데 바로 **하이픈** 이다. 저자들은 $k-distance(p)$와 같이 자꾸 변수에 하이픈을 넣는데 이러한 노테이션은 마치 $k$ **minus** $distance(p)$ 와 같이 이해된다. 어지간하면 참고 쓰려고 했는데 가독성이 너무 떨어져서 도저히 쓸 수 없다. 왜 이런 노테이션을 쓰는지 도저히 이해할 수 없다. 그래서 변수에 정의된 하이픈은 모두 닷으로 바꾸겠다. 즉 $k-distance(p)$를 $k.distance(p)$와 같이 변경하겠다. 

- 이거는 HST를 쓰기위해서 어쩔수 없이 잘 읽어봐야 한다. 

### 4. Formal definition of local outliers 
- **(Definition 3)** 여기에서는 **점 $p$와 $k$번째로 가까운 점사이의 거리*$k.distance(p)$*** 라는 것을 정의한다. $p$와 가장 가까운 점은 자기자신이므로 $k=1$이면 $k.distance(p)=0$이다. 즉 모든 경우에 클리어하게 아래가 정의된다. 
\begin{align}
1.distance(p)=d(p-p)=0
\end{align}
그런데 만약에 점 $p$로부터 $k$번째로 가까운 점이 2개면 정의가 애매해진다. 이때는 그냥 동점자끼리는 같은 거리를 가진다고 생각하고 정의해버린다. 예를 들어보자. 하나의 수직선위에 점 $\\{-1,0,1,2,3,4\\}$가 있다고 하자. 편의상 $p=0$이라고 하자. 일단 언급한바와 같이 아래가 성립한다. 
\begin{align}
1.distance(0)=0
\end{align}
이다. $k=2$인 경우를 살펴보자. 점 $\\{0\\}$과 두번째로 가까운 점은 $\\{-1,1\\}$ 이런경우는 아래와 같이 정의한다. 
\begin{align}
2.distance(0)=3.distance(0)=1
\end{align}
**앞으로는 논의를 빠르게 하고 논문의 이해를 돕기위해서 위와같은 상황은 없다고 가정하자.**

- **(Definition 4)** 여기에서는 **점 $p$의 $k.distance$ 이웃들*($k.distance$ neighborhood of $p$)*** 이라는 개념이 나온다. 요거는 기호로 $N_{k.distance(p)}(p)$라고 표현하고 아래와 같이 정의한다.
\begin{align}
N_{k.distance(p)}(p)=\\{q \in D- \\{p\\} | d(p,q) \leq k.distance(p) \\} 
\end{align}
여기에서 $D$는 전체 데이터셋을 의미한다. 쉽게 말하면 $p$의 $k.distance$ 이웃들 점 $p$와 가까운 점 $k-1$개를 의미한다. (자기자신을 빼므로 $k$개가 아니라 $k-1$개임). 이것을 줄여서 $N_k(p)$라고도 쓴다. 

- 그리고 편의상 앞으로 $N_k(p)$의 원소들을 $p$의 $k$-1차이웃 혹은 줄여서 1차이웃이라고 하자. 요런 정의를 바탕으로 하면 $k.distance(p)$는 $p$의 $k$-1차이웃들중 $p$와 가장 멀리떨어진 점과의 거리를 의미한다. 편의상 이걸 *최대 $k$-1차이웃거리* 혹은 *최대 1차이웃거리* 라고 하자. 이런 용어는 논문에 없는 용어이다. 비슷한 방식으로 1차이웃들의 1차이웃들을 정의할수 있는데, 이를 2차이웃으로 정의하자. 앞으로 혼란을 피하기 위해서 (1) $p$는 target point (2) $q$는 $p$의 1차이웃 (3) $o$는 $q$의 1차이웃 즉 $p$의 2차이웃으로 정의하자. 즉 아래와 같은 인덱스로 정리하자. 
\begin{align}
q \in {\cal N}_ p :=\\{q \in D- \\{p\\} | d(p,q) \leq k.distance(p) \\} \\\\ \\ 
\forall q: ~ o \in {\cal N}_ q :=\\{o \in D- \\{q\\} | d(q,o) \leq k.distance(q) \\} 
\end{align}

- **(Definition 5)** 여기에서는 $q$에서 $p$까지의 **리처빌리티-디스턴스*(Reachability Distance, RD)*** 를 정의한다. RD는 기호로 $reach.dist_{k}(p,q)$라고 쓰고 아래와 같이 정의한다. 
\begin{align}
reach.dist_{k}(p,q)= \max (k.distance(q) ,d(p-q)) 
\end{align}
정의만 봐도 알수있는건 RD는 항상 유클리드 거리보다 같거나 큰 값을 가진다는 것이다. (그리고 RD가 유클리드 거리보다 큰 값을 가지는 경우는 $o$의 $k$-1차이웃에 해당하는 점들이다.) 

- 아래 그림에서 점선으로 된 원은 중심이 $o$이고 반경이 $4.distance(o)$이다. 이 점선원의 내부에 위치한 점들은 $N_k(o)$원소들이다. 따라서 점선원의 반지름은 최대 1차이웃거리값이 되며 점선원의 내부에 있는 점들은 $o$의 1차이웃들이 된다. <br/> 
**(1)** 점 $p$가 $o$의 1차이웃이면 $reach.dist_k(p,o)$는 최대 1차이웃거리 즉 점선원의 반지름값이다. <br/>
**(2)** 점 $p$가 $o$의 1차이웃이 아니면 $reach.dist_k(p,o)$는 그냥 유클리드 거리값이다. <br/>
<center><img src="https://github.com/miruetoto/miruetoto.github.io/blob/master/img/LOF/fig2.png?raw=true" width="60%" height="60%"></center>

- 가장 단순하면서도 중요한 사실은 위의 그림에서 점선원의 반지름이 커질수록 RD값도 커진다는 것이다. 

- 여기에서 $k$는 어떠한 역할을 할까? 극단적으로 생각해서 $k$가 엄청 크다고 하자. 예를 들어서 $k=\|D\|$라고 하자. 그럼 그림 2에서 점선원의 반지름은 $o$와 가장 떨어진 점과의 거리와 같게되고 모든점들은 점선원의 내부에 포함되게 된다. 따라서 이 경우 $reach.dist_{k}(p,o)$의 값은 점 $o$와 가장 멀리 떨어진 점과의 거리로 고정된다. $k$가 엄청작으면 점선원은 $o$ 자기자신만 포함하는 원이 될테고 모든 점들은 점선원 외부에 있게 된다. $reach.dist_{k}(p,o)$ 의 값은 그냥 $p$와 $o$와의 유클리드 거리가 된다. 

- 이제 $k$가 고정되었다고 생각해보자. 특이한 점은 고정된 $k$에 대하여서도 $o$의 주위에 점들이 얼마나 밀도있게 뭉쳐있느냐에 따라서 그림2의 점선원의 반지름이 달라진다는 것이다. 그리고 이 것은 점 $o$와 $p$의 $reach.dist_k$값 역시 달라지게 만든다. 

- 종합하면 $reach.dist_{k}(p,o)$는 3가지 요소에 따라서 그 값이 달라진다. <br/><br/>
(1) 기본적으로 점 $k$와 점 $o$가 떨어져 있는 유클리드 거리 <br/>
(2) 점 $o$의 주변에 있는 점들이 얼마나 빽빽하게 모여있는지를 가늠하는 정도 <br/>
(3) $k$값 

- 저자들은 이 $k$를 Minpts라고 표현한다. 정확한 의미는 모르겠지만 ***minimal number of points***의 약자인것 같다. 여기에서는 그냥 계속 $k$라고 표현하겠다. 

- 잘 살펴보면 이 논문에서 RD는 target point $p$ 주변의 점들의 **조밀함** 을 반영한 거리라고 볼 수 있다. 무슨 말인지 예를 들어 설명해보도록 하자. 점 $p$와 유클리드 거리상으로 똑같은 거리에 있는 두점 $o_1$과 $o_2$가 있다고 생각하자. 그런데 점 $o_1$ 주변에는 다른점들이 엄청 조밀하게 있고 점 $o_2$ 주변에는 다른점들이 듬성듬성 있다고 하자. 고정된 $k$에 대하여 $o_1$주변으로는 작은점선원이 $o_2$주변으로는 큰 점선원이 그려질 것이다. <br/>
(1) $p$가 $o_1$의 점선원과 $o_2$의 점선원에 모두 포함될 경우: 
\begin{align}
reach.dist(p,o_1)<reach.dist(p,o_2).
\end{align}
(2) $p$가 $o_1$의 점선원에는 포함되지 않지만 $o_2$의 점선원에는 포함되는 경우:
\begin{align}
reach.dist(p,o_1) \leq reach.dist(p,o_2).
\end{align}
(3) $p$가 $o_1$과 $o_2$의 점선원에 모두 포함되지 않는 경우:
\begin{align}
reach.dist(p,o_1)=reach.dist(p,o_2).
\end{align}
따라서 실제 유클리드 거리는 같음에도 불구하고 RD의 관점에서 보면 $o_1$보다 $o_2$가 더 떨어져있다. 

- 비유를 하면 $o_1$은 다른점들과도 두루두루 가까운 점이고 $o_2$는 다른점들과 가급적 멀리 떨어져 있는 점이다. 점 $o_1$은 기본적으로 **"나는 모든점들과 가까워"** 라고 생각하는 점이고 $o_2$는 기본적으로 **"난 모든점들과 멀어"** 라고 생각하는 점이다. 이 경우 실제로 $d(o_1,p)$ 와 $d(o_2,p)$가 같다고해도 $o_1$과 $p$를 더 가까운 사이라고 생각하는 것이다. (점 $o$들이 본질적으로 가지는 기본생각을 존중한다고 비유하여 생각할 수 있음) 

- 잠시 RD와 HST의 **쌓인눈거리*(snow-dist)*** 를 비교하여 보자. <br/><br/>
(1) RD에서 점선원안에 들어오는것을 이웃으로 생각하는데 HST에서는 링크된 점들을 이웃으로 생각한다. 즉 RD에서는 target point와 가장 가까운 유클리드 거리를 가지는 몇개의 점들을 이웃으로 생각하고 HST는 target point와 링크된 점들을 이웃으로 생각한다. HST에서는 다른 링크를 줄 수 있으므로 이웃의 정의를 전혀 다르게 가져갈 수 있다. <br/> 
(2) 이 논문에 나오는 산점자료들을 굳이 HST에 때려맞춰서 그래프시그널 형태로 표현한다면, 점 $(1,1)$은 위치가 $(1,1)$에서 그 크기로 $\sqrt{2}$를 가지는 신호로 표현가능하다. <br/>
(3) RD는 주변점들의 국소적 특징들을 반영한다는 점에서 HST의 snow-dist와 비슷하다. 그리고 둘다 기본적으로 유클리드 거리를 반영한다는 점에서 비슷하다. 다만 RD는 주변값들이 얼마나 조밀한지 그렇지 않은지를 추가적으로 반영하고 snow-dist는 주변값들보다 상대적으로 낮은지 높은지, 낮아지다가 높아지는지 등등을 반영할 수 있다. 하트모양으로 point를 scattering 한다고 할때 하트의 꼭지점을 찾을 수 있다. 비유를하면 RD는 주변점들의 밀도를 느낄 수 있으며 snow-dist 모양을 느낄 수 있다!!!! <br/>
(4) snow-dist 로 RD 와 비슷한 역할을 하게 만들수 없을까?? 밀도가 높은곳이라면 연결이 많이 되어있을테고 링크가 많을수록 수렴하는 느낌이 다를텐데 이걸 이용해서 먼가 할 수 있을까?? 

- **(Definition 6)** 이제 **로칼-리처빌리티-덴시티*(Local Reachability Density,LRD)*** 에 대하여 알아보자. 점 $p$의 LRD는 는 아래와 같이 정의한다. 
\begin{align}
lrd_{k}(p)=\left(\frac{1}{\|N_{k}(p)\|} \sum_{o \in N_{k}(p)} reach.dist_k(p,o)\right)^{-1}
\end{align}
이게 논문에서는 $k$대신에 Minpt를 사용하였다. $o$대신에 $q$를 대입하면 아래와 같이 된다. (후에는 $p$의 1차이웃을 $q$, 그리고 $q$의 1차이웃을 $o$라고 정의하는데 이러한 정의에 통일감을 주기 위해서 아래와 같이 정의하자.) 
\begin{align}
lrd_{k}(p)=\left(\frac{1}{\|N_{k}(p)\|} \sum_{q \in N_{k}(p)} reach.dist_k(p,q)\right)^{-1}
\end{align}

- LRD의 정의에서 RD대신에 유클리드거리를 쓰면 그냥 **평균거리의 역수**가 되어서 빼도박도 못하고 밀도개념이 된다. $p$의 1차이웃들의 집합을 편의상 ${\cal N}$이라고 하자. 그러면 LRD는 대충 
\begin{align}
lrd_{k}(p):= \mbox{average}\Big(dist(p,q)\Big),~ q \in {\cal N} 
\end{align}
의 느낌밖에가
- 

- 이 정의는 살짝 오묘한게 다음과 같은 방식으로 구해진다. <br>
**step1** $k$를 고정한다. <br/>
**step2** 점 $p$를 중심으로 점선원을 펼치고 점 $p$의 1차이웃을 구한다. 이 이웃들을 
\begin{align} 
q_1,\dots,q_k 
\end{align}
라고 하자. <br/>
**step3** $q_1,\dots,q_k$를 중심으로 다시 점섬원을 펼친다. 이때 점선원들의 반지름은 각각 다를것이다. 그리고 이 각각의 반지름 안에 $p$가 포함될수도 있고 아닐수도 있다. <br/>
**step4** 각각의 $q_1,\dots,q_k$를 기준으로 하여 $p$와의 RD를 구하여 이 값들을 평균낸다. 그리고 그것의 역수를 취한다. <br/> 

- $lrd_k(p)$ 의 값이 크려면 
\begin{align}
\frac{1}{\|N_{k}(p)\|} \sum_{q \in N_{k}(p)} reach.dist_k(p,q)
\end{align}
의 값이 작아야 한다. 이 값이 작기 위해선 $q_1,\dots,q_k$와 $p$의 RD값들이 작아야 하고 이를 위해서는 **step3**에 해당하는 점선원의 반지름값이 모두 작아야 한다. 그러기 위해서는 $q_1,\dots,q_k$ 주변에 점들이 조밀조밀하게 모여있어야 한다. 

- 어떻게 보면 $lrd_k(p)$는 점 $p$가 특정 클러스터에서 얼마나 중심에 위치해 있느냐를 메저한다고 볼 수 있다. 그런데 이걸 판단하기 위해 $p$의 조밀성 뿐만 아니라 $q$의 조밀성도 같이 따진다는 것이 특이한 점이다. 하나씩 따져보자. 
(1) $p$근처에 점들이 빽빽하게 모여있으며 $q_i$근처에도 점들이 빽빽하게 모여있음. <br/>
(2) $p$근처에 점들이 빽빽하게 모여있지만 $q_i$근처에는 상대적으로 덜 빽빽함. (태양모양, $p$가 태양중심) <br/>
(3) $p$근처에 점들이 듬성듬성 있지만 $q_i$근처에는 빽빽함. (도넛모양, $p$가 도넛중심) <br/>
우선 (1)의 경우가 가장 밀토가 높으므로 이 경우에 $lrd_k(p)$의 값이 가장 큰 것은 자명하다. (2)와 (3)중에는 어떤값이 더 밀도가 낮을까? (2)의 경우에 $p$을 중심으로 한 반경은 작지만 $q_i$를 중심으로한 반경은 크게 될 것이다. 이 경우 $q_i$의 반경들이 **RD**값으로 결정된다. (3)의 경우에는 $p$ 중심의 반경은 크지만 $q_i$의 반경들은 작을 것이다. 이 경우 $p$와 $q_i$간의 거리가 **RD**으로 결정된다. 즉 (2)가 큰지 (3)이 큰지 알 수 없는 상황이 된다. (아마 일반적으로 밀도를 측정하는 메져라면 (2) 의 경우를 더 밀도감 있게 볼 것 같음) 

그런데 이 값은 (1) $p$ 근처에 점들이 빽빽하게 모여있으며 (2) $p$의 1차이웃들도 근처에 점들이 빽빽하게 있어야 커진다. 여기에서 (2)는 당연해 보이지만 (1)은 당연해 보이지 않을 수 있다. 즉 (1)은 lrd와 상관이 없다고 여겨질 수 있다. 하지만 $q_1\dots,q_k$ 근처에 점들이 아무리 빽빽하게 있어도 일단 $p$ 근처에 점들이 듬성듬성 있으면 **step4**의 RD가 거의다 는 최소한 **step2**의 점선원의 반지름보다는 크다는 성질이 있으므로 lrd값이 작아지게 된다. 

- 이해와 암기를 돕기위해서 좀 세속적인 비유를 해보자. 점 $p$가 얼마나 **인싸**인지를 클러스터의 중심점인지를 측정하기 위해서는 (1) 점 $p$ 근처에 얼마나 많은 이웃 혹은 친구들이 있는지 (2) 점$p$의 이웃 혹은 친구들은 서로가 얼마나 친한지를 모두 보아야 한다는 것이다. 계속 비유를 해보자. 두명의 사람 $p$와 $p'$이 있다고 하자. $p$와 $p'$이 친한 친구는 모두 똑같이 5명인데, 이 $p$와 친한 이 5명은 서로서로도(=끼리끼리도) 모두 친하다(즉 5명모두 인싸라고 생각가능). 그런데 $p'$가 친한 5명은 서로서로가 친하지 않다. 그러면 $p$가 더 인싸라고 생각한다는 것이다. 즉 본인이 잘나가는(=인싸인) 정도를 판단하려면 본인자체가 잘나가는(=친구가많은)것도 중요하지만 본인 주변의 친구들이 얼마나 잘나가는지도 살펴보아야 한다는 것이다. 

- **(Definition 7)** 이제 대망의 **LOF(local outlier factor)** 를 정의하여보자. LOF는 아래와 같이 정의한다. 
\begin{align}
LOF_{k}(p)=\frac{1}{\|N_{k}(p)\|} \sum_{o \in N_{k}(p)} \frac{lrd_k(o)}{lrd_k(p)}
\end{align}
이건 그냥 너무 클리어한 정의이다. $p$근처에는 점이 하나도 없고 $p$의 이웃들은 다 모여있는 경우가 $p$의 LOF가 가장 크게 나타난다. 

- 점 $p$가 클러스터 안에 폭 파묻혀 있다면 $p$의 LOF값은 1에 가까울 것이다. 즉 $LOF_{k}(p) \approx 1$ 이다. 

### Properties of local outliers 

#### LOF for Objects Deep in a Cluster 

- 논문의 Fig 1 에서 $o_2$는 아웃라이어로 판단하고 클러스터 $C_1$에 존재하는 다른 모든점들은 아웃라이어가 아니라고 판단하는 것이 우리의 목표이다. 

<center><img src="https://github.com/miruetoto/miruetoto.github.io/blob/master/img/LOF/fig1.png?raw=true" width="60%" height="60%"></center>

- 즉 $o \in C_1$ 이면 $LOF_k(o) \approx 1$이 성립하게끔 하는것이 우리의 목표다. 우리가 정의한 LOF가 과연 이러한 성질을 만족할까? Lemma1은 $C_1$에 존재하는 모든 점들은 아웃라이어가 아니라는 결론을 주는(정말?? 좀 애매한데? ㅋㅋ) 레마이다. 

- **(Lemma 1)** $C$를 임의의 클러스터라고 하자. $reach.dist.min$ 이라는 것을 정의할 것인데 이것은 $C$내에 있는 모든 자료의 **리치어빌리티-디스턴스**의 최소값을 의미한다. 즉 클러스터 $C$내에서 가장 가까이 붙어있는 두점사이의 거리를 의미한다. 식으로 쓰면 아래와 같다. 
\begin{align}
reach.dist.min=\min \\{ reach.dist(p,q): p,q \in C \\}
\end{align}
이와 유사하게 $reach.dist.max$ 도 정의할 수 있다. 이제 $\epsilon$을 아래와 같이 정의하자. 
\begin{align}
\epsilon=\frac{reach.dist.max}{reach.dist.min}-1
\end{align}
쉽게 생각해서 $C$안의 대부분의 점들의 엄청 모여있으면 $\epsilon \approx 0$ 와 같이 된다. 저자들은 (i) $p$의 $k$-근접이웃들이 모두 $C$의 원소이고(ii) $p$의 $k$-근접이웃들 각각의 $k$-근접이웃들까지 모두 $C$의 원소이면 
\begin{align}
\frac{1}{1+\epsilon}\leq LOF(p) \leq 1+\epsilon
\end{align}
이 성립한다고 주장한다. 

- 증명은 다음과 같다. 모든 $q \in N_k(p)$에 대하여 아래가 성립한다. 
\begin{align}
dist(p,q) \geq reach.dist.min
\end{align}
따라서 아래가 성립한다. 
\begin{align}
lrd_k(p) \leq \frac{1}{reach.dist.min}
\end{align}
이거랑 비슷한 논리로 아래가 성립한다. 
\begin{align}
lrd_k(p) \geq \frac{1}{reach.dist.max} 
\end{align}
위의 논쟁에서 $p$를 $q$로 바꾸고 $q$를 $o$로 바꾸면 아래 역시 증명된다. 
\begin{align}
\frac{1}{reach.dist.max} \leq lrd_k(q) \leq \frac{1}{reach.dist.min}
\end{align}
따라서 원하는것이 증명된다. 

- 아무튼 Lemma 1 을 잘 살펴보면 $\epsilon$이 클러스터의 tightness를 결정하고 (i)과 (ii)는 점 $p$가 얼마나 클러스터안에 **"포오옥~"** 파묻혀있는지 메져함을 알수있다. 

- ***요걸 잘 살펴보면 HST에서 $\tau \to \infty$일때 $\epsilon_{\tau} \to 0$으로 감을 증명하고, (즉 클러스터가 점점 tight해짐을 증명하고) $p$가 얼마나 클러스터에 파묻히는지 (혹은 파묻히지 않는지)를 보이면 (1) HST가 평균이 다른 그룹들을 어떻게 분리하는지 (2) 어떻게 outlier를 찾아내는지 (3) 어떻게 변화점을 포착하는지에 대한 증명이 의외로 쉬울 수 있다. 요 생각 좀 더 구체화하면 좋을듯.. ***
 
#### A General Upper and Lower Bound on LOF 

- Lemma 1 은 (i), (ii)가 만족되는 $p \in C$에 대한 성질만 밝혔다. 좀더 일반적인 $p$에 대한 성질을 밝히기 위하여 Theorem 1을 만들었다. Theorem 1 은 두가지 측면에서 Lemma 1의 업그레이드 버전이라고 볼 수 있다. 첫째 Theorem 1 은 언급한데로 일반적인 $p$에 대하여 $LOF_k(p)$의 bound를 준다. 둘째 Theorem 1 은 Lemma 1 보다 더 타이트한 bound를 제시할 수 있다. 

- Theorem 1 을 제시하기에 앞서 몇 가지 정의할 기호들이 있다. 
\begin{align}
direct_{min}(p)=\min \\{ reach.dist(p,q) : q \in N_k(p) \\}
\end{align}
\begin{align}
direct_{max}(p)=\max \\{ reach.dist(p,q) : q \in N_k(p) \\}
\end{align}
\begin{align}
indirect_{min}(p)=\min \\{ reach.dist(q,o) : q \in N_k(p), ~ o \in N_k(q) \\}
\end{align}
\begin{align}
indirect_{max}(p)=\max \\{ reach.dist(q,o) : q \in N_k(p), ~ o \in N_k(q) \\}
\end{align}

- 또한 "$p$의 $k$-근접이웃"을 "$p$의 직접이웃"으로 명하고 "$q$의 $k$-근접이웃"을 "$p$의 간접이웃"으로 정의하자. (단 이때 $q$는 $p$의 직접이웃들임) 

- **(Theorem 1)** 아래식이 성립한다.
\begin{align}
\frac{direct_{min}(p)}{indirect_{max}(p)}\leq LOF_k(p) \leq \frac{direct_{max}(p)}{indirect_{min}(p)}
\end{align}

- Lemma 1의 업그레이드 버전이긴 하지만 그다지 인상적인 직관을 나에게 주는것 같지는 않다. 저자도 이를 의식해서 그런지 이에 대한 직관을 다음절에 설명하였다. 

#### The Tightness of the Bounds

- 논의에 앞서 아래와 같은 것을 정의하자. 
\begin{align}
direct(p)=\frac{direct_{min}(p)+direct_{max}(p)}{2}
\end{align}
\begin{align}
indirect(p)=\frac{indirect_{min}(p)+indirect_{max}(p)}{2}
\end{align}
혼란의 여지가 별로 없다면 $direct(p)=direct$라고 정의하고 $indirect(p)=indirect$라고 정의한다. 

- 편의상 Theorem 1 에서 정리된 $LOF_k(p)$의 lower bound 를 $LOF_{min}$이라고 하고 그 max에 해당하는 것을 $LOF_{max}$라고 하자. 저자들은 $LOF_{max}-LOF_{min}$이 $\frac{direct}{indirect}$에 의존한다고 주정한다. 즉 
\begin{align}
LOF_{max}-LOF_{min} \propto \frac{direct}{indirect}=\frac{direct_{min}(p)+direct_{max}(p)}{indirect_{min}(p)+indirect_{max}(p)}
\end{align}

- 아래를 가정하자. (이거 꽤나 크리티컬한 가정같은데..)
\begin{align}
\frac{direct_{max}-direct_{min}}{direct}=\frac{indirect_{max}-indirect_{min}}{indirect}
\end{align}
이것은 $k$의 직접이웃(direct-neighborhood)와 $k$의 간접이웃(indirect-neighborhood)의 출렁임(fluctuate)가 동일하다고 가정하는것과 같다. 즉 $k$의 직접이웃과 간접이웃의 분산구조가 같다고 가정한다는 의미이다. 아무튼 이러한 가정덕에 우린 $pct=x\%$라는 하나의 파라메터로 직접 혹은 간접이웃들의 출렁임을 아래와 같이 표현할 수 있다. 
\begin{align}
direct_{max}=direct\times (1+x\%) 
\end{align}
\begin{align}
direct_{min}=direct\times (1-x\%) 
\end{align}
$indirect$의 경우도 마찬가지이다. 

- 아무튼 저자들이 주정하고 싶은것은 Theorem 1 에서 정리된 $LOF$의 경계값이 $\frac{direct}{indirect}$에 의존한다는것과 그 바운드가 상당히 작다는것 같다. (그림4에서 보면 진짜 작아보임) 나는 크게 이 내용에 관심이 없다. 

#### Bounds for Objects whose Direct Neighborhoods Overlap Multiple Clusters

- 이전에서는 바운드의 tightness를 다루었고 그 바운드가 tight하기 위한 2가지 조건을 살펴보았다. (정말? 그런게 있었어??) 이제우리의 질문은 "그럼 바운드가 타이트하지 않으면 어떻게 되는거야?"라는 것이다. 


### The impact of the parameter minpts 

