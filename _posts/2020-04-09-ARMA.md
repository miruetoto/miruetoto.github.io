---
layout : post 
title : (강의) ARMA 
---

### About this doc 

- 이 문서에서는 ARMA모델에 대하여 다룬다. 

### Wold의 관찰 (교재 5.2.4.)
- Wold는 임의의 정상확률과정이 결정적성분과 비결정적 성분의 합으로 구분가능하다고 주장하였다. 즉 임의의 정상확률과정 $X_t$는 
\begin{align}
\begin{cases}
X_t =& \eta_t + Z_t\\\\ \\
Z_t =& \epsilon_t+\psi_{1}\epsilon_{t-1}+\psi_{2}\epsilon_{t-2}+\dots =\sum_{j=0}^{\infty}\psi_j \epsilon_{t-j}
\end{cases}
\end{align}
와 같이 표현할 수 있다. 

- 여기에서 $\eta_t$ predictable한 성분을 의한다. 구체적으로는 $x_{t-1},x_{t-2},\dots$이 주어졌을 경우 $\eta_t$의 값을 완벽히 예측할 수 있을때 $\eta_t$를 deterministic하다고 한다. $\eta_t$가 랜덤이 아니라는 의미가 아니라는 것에 유의하자. 

- 여기에서 $\psi_0,\dots,\psi_{\infty}$의 값은 유일하게 결정할 수 있다. 이때 $\psi_0=1$이다. (이 정리가 거의 사기적이다.)

- 우리의 수준에서는 임의의 정상시계열 $\\{Z_t\\}$에 대하여 아래의 두 식을 만족하는 계수 $\psi_j$를 선택할 수 있다고 이해할 수 있다. 
\begin{align}
\begin{cases}
Z_t= \epsilon_t+\psi_{1}\epsilon_{t-1}+\psi_{2}\epsilon_{t-2}+\dots =\sum_{j=0}^{\infty}\psi_j \epsilon_{t-j}\\\\ \\
\sum_{j=0}^{\infty}\psi_j^2<\infty
\end{cases}
\end{align}

- 이 정리의 관찰은 매우 쉽다. $Z_t=0.5Z_{t-1}+\epsilon_t$에 대하여 
\begin{align}
Z_t=\epsilon_t+0.5\epsilon_{t-1}+0.5^2\epsilon_{t-2}+\dots 
\end{align}
꼴로 정리되는 것은 이미 여러번 보였는데 이것이 그 예라고 할 수 있다. 

- 여기에서 
\begin{align}
Z_t =\epsilon_t+\psi_{1}\epsilon_{t-1}+\psi_{2}\epsilon_{t-2}+\dots =\sum_{j=0}^{\infty}\psi_j \epsilon_{t-j}
\end{align}
의 꼴은 무한MA과정, 즉 MA($\infty$)로 부르기도 한다. 참고로 MA(1)과정은 
\begin{align}
Z_t =\epsilon_t-\theta_{1}\epsilon_{t-1}
\end{align}
으로 표현하며 MA(2)과정은 
\begin{align}
Z_t =\epsilon_t-\theta_{1}\epsilon_{t-1}-\theta_{2}\epsilon_{t-2}
\end{align}
와 같이 표현한다. 

- MA과정은 그 자체로는 큰 의미가 없지만 (개인적인 생각임) 정상인 AR과정을 고려해야만 하는 이론적인 토대를 제공해주는 것에 큰 의미가 있다. 우선 쉽게 아래의 사실을 관찰할 수 있다.  <br/><br/>
**(1) 정상확률과정은 모든 lag에 대한 ACF의 값들을 더한값이 유한해야 한다.** <br/><br/>
이것이 성립하는 이유는 간단한데 $Z_t$가 정상인 AR이라면 
\begin{align}
\begin{cases}
Z_t= \epsilon_t+\psi_{1}\epsilon_{t-1}+\psi_{2}\epsilon_{t-2}+\dots =\sum_{j=0}^{\infty}\psi_j \epsilon_{t-j}\\\\ \\
\sum_{j=0}^{\infty}\psi_j^2<\infty
\end{cases}
\end{align}
를 만족하는 $\psi_j$의 값들이 유일한데 $\sum_{j=0}^{\infty}\psi_j^2<\infty$에 의해서 바로 원하는 성질이 성립함을 알 수 있다. 

- 반대로 아래의 사실도 쉽게 관찰할 수 있다. <br/><br/>
**(2) 모든 lag에 대한 ACF의 값들을 더한값이 유한하면 정상확률과정이다.** <br/><br/>
이것 역시 귀류법을 사용하면 쉽게 참임을 증명할 수 있다. 

### AR(1) 
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. 정상성 가정하에 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: AR(1)은 마코프과정이라고도 부름. AR(1)에서 $\phi=1$인 경우는 랜덤워크라고 부름. 

### AR(2)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건(이론)
4. 정상성 가정하에 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF
8. 기타특징: 특성방정식의 근의 형태에 따라서 ACF의 모양이 다름. 

### AR(p)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. 정상성 가정하에 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### AR류의 모델에 대한 일반적 특징 


### MA(1)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. ~~정상성 가정하에~~ 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### MA(2)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. ~~정상성 가정하에~~ 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### MA(q)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. ~~정상성 가정하에~~ 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### 쌍대성 
1. (정상이든 비정상이든) AR(p)는 항상 MA($\infty$)로 표현가능하다. 
2. (가역이든 비가역이든) MA(q)는 항상 AR($\infty$)로 표현가능하다. 
3. 정상-AR(p)과정은 가역-MA($\infty$)과정으로 표현가능하다. 
4. 가역-MA(q)과정은 정상-AR($\infty$)과정으로 표현가능하다. 
5. 무한 MA표현의 장점: 관측값을 $iid$-확률오차들의 합으로 표현가능하다. 
6. 무한 AR표현의 장점: 관측불가능한 확률오차를 관측값들로 표현가능하다. (예측에 강점을 가짐)

### ARMA(1,1)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. 정상성 가정하에 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### ARMA(p,q)
1. 정의: 수식, 후진작용소, MA로 표현 
2. 특성방정식 
3. 정상성조건 
4. 정상성 가정하에 평균과 분산 
5. 가역성조건 
6. ACF
7. PACF 
8. 기타특징: 

### 실전 
1. 시계열 그림을 그린다. 
2. 정상성을 체크한다. (1) 눈으로 체크한다. (2) SACF, SPACF 를 찍어본다. (3) ADF-test를 한다. / 비정상 시계열이라면 분석하지 않는다. 
3. 정상이라면 모델을 특정시킨다. 
4. 모수를 추정한다. 
5. 모형이 타당한지 진단한다. (잔차분석)

