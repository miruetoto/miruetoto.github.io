---
layout: post
title: (정리) 모델링 혹은 모형선택
---
### About this post 
- 본 포스트에서는 다양한 모델링에 대하여 소개한다. 본 포스팅에서는 하나의 모형에서 최적의 변수선택을 하는방법(라소 혹을 리지)이 아닌 전체적으로 모델링을 하는 방법에 따른다. 

- 본 포스팅의 내용은 내 주관이 상당히 많이 들어간 내용이며 교재의 내용을 바탕으로 재구성한것은 아니다. 

- (나를 포함하여) 많은 사람들이 선형모델/비선형모델, 파라메트릭/세미파라메트릭/넌파라메트릭, 어디티브/멀티플리케이티브 모델등을 엄밀하게 구분하지 못하는데 이것에 대하여 조금 정리하고 싶어 포스팅을 시작했다. 

--- 

### 선형모델 / 비선형모델 
- 모델링이란 
\begin{align}
y_i=f(x_i)+\epsilon_i
\end{align}
의 꼴에서 $f$의 모양을 결정하는 과정을 의미한다. 이때 $f$는 베이시스와 파라메터로 구성된다. 그런데 이때 $f$가 아래와 같이 
\begin{align}
f = \sum basis \times coef
\end{align}
꼴의 형태로 표현할 수 있다면 이 모델을 선형모델이라고 하고 그렇지 않으면 비선형모델이라고 한다. 

- 많은 사람들이 $f(x)$가 $x$에 대하여 선형이면 선형모델이라고 생각하는데 이건 사실이 아니다. 이것은 $f$가 $x$에 대하여 비선형이라도 파라메터 $\beta$에 대하여 선형이라면 선형모델이라고 한다. 중학교 1학년때 배우는 방정식을 보면 기준을 $x$로 보느냐 $y$로 보느냐에 따라 1차식이 되기도 하고 2차식이 되기도 하는 수식을 보았을 것이다. 예를들어보자. 
\begin{align}
x^2 y= 0
\end{align} 
은 이 1차식인가 2차식인가? 이것은 $x$에 대한 2차식이지만 $y$에 대한 1차식이다. 이와 유사하게 
\begin{align}
f(x)=\beta_0+\beta_1 x + \beta_2 x^2
\end{align}
은 $x$에 대하여는 비선형이지만 $\beta=(\beta_0,\beta_1,\beta_2)'$에 대해서는 선형이다. 

- $f$를 추론하는 과정은 (1) 적당한 베이시스를 선택하고 (2) 알맞는 파라메터를 구하는 과정으로 나눌 수 있는데 이때 (2)의 과정에서 $f$가 파라메터에 대한 선형함수이면 여러가지 좋은 성질이 있다. 그리고 이러한 선형모델을 푸는 모든 방법은 일반적인 회귀분석을 수행하는 방법과 거의 동일하다. 

- 선형모델이 반드시 파라메트릭 모델일 필요는 없다. 회귀모델, 폴리노미알 리그레션, 아노마, 로지스틱, 로그선형모델 등 GLM류로 정리되는 모델드은 선형모델이면서 파라메트릭모델이다. 또한 퓨리에변환/웨이블릿 변환은 선형모델이지만 세미파라메트릭 모델이다. 

### 파라메트릭 / 세미파라메트릭 / 넌파라메트릭 

- 앞에서 말했듯이 모델링이란 
\begin{align}
y_i=f(x_i)+\epsilon_i
\end{align}
의 꼴에서 $f$의 모양을 결정하는 과정을 의미한다. 

- $f$의 모양을 결정할때 데이터에 대한 확실한 사전정보가 있는 경우가 있다. 예를들어 
''$f(x)$는 $x$에 선형변환으로 만들어질 수 있다. (즉 $f(x)=\beta_0+\beta_1x$)'' 
라는 사실을 알고 있는 경우이다. 이는 
\begin{align}
y_i=f(x_i)+\epsilon_i, 
\end{align}
와 같은 모델에서 $f$가 어떠한 형태를 가질것인지 미리 알고 있다고 생각한다는 말과 같다. 이처럼 $f$가 어떤 모양인지 미리 알고 접근하는 방법을 파라메트릭 모델링이라고 한다. 

- 사전정보가 없어서 $f$를 어떻게 모델링할지 감이 안 올 수도 있다. 즉 자료를 봤는데 선형의 모양을 가지는지 어떤지 감을 못잡겠는 경우이다. 이것을 바꾸어 말하면 $\\{y_i\\}$가 $\\{x_i\\}$의 어떤 space에 있는지 감을 못 잡겠다는 뜻이다. 혹은 모델링이 귀찮을 수도 있다. 이럴 경우 $f(x)$가 $x$의 어떤 특정스페이스 $\cal A$의 부분공간에 존재한다고 가정하고 그 특정스페이스 $\cal A$를 expansion할 수 있는 베이시스를 선택하여 문제를 풀 수 있다. 가령 예를들면
''$f(x)$가 어떤 공간에 있는지 모르겠는데 최소한 비숍스페이스의 부분공간에 있는것 같아'' 
라고 생각한다면 웨이블릿 베이시스를 선택하여 모델링 하는 것이다. 보통 위와 같은 접근법은 무한대의 basis를 활용한다. 많은 수학자들이 
"이런식으로 무한개의 basis를 활용하면 특정공간에 있는 어떠한 함수도 표현할 수 있어요~"
라는 식의 증명을 많이 해놓았는데 이러한 증명결과들을 적극적으로 활용하는 셈이다. 요렇게 $f$를 표현하는데 무한개의 basis를 활용하는 모델링을 semi-parametric이라고 한다. 

- 파라메트릭 모델링도 못하겠고 세미파라메트릭 모델링도 못하겠다면 넌파라메트릭 모델링을 할 수 있다. 넌파라메트릭 모델링은 커널을 사용하여 자료를 표현하는 방식을 의미한다. 커널은 베이시스를 설계하는 룰 자체에 입력표본 $x_i$을 사용하는 방식이다. 구체적으로는 $f(x)$를 아래와 같이 가정하는 것으로 이해할 수 있다. 
\begin{align}
f(x)=e^{-\frac{\\| x-x_1\\|}{2h^2}}\beta_1+e^{-\frac{\\| x-x_2\\|}{2h^2}} \beta_2+\dots+e^{-\frac{\\| x-x_n\\|}{2h^2} }\beta_n
\end{align}
특이한것은 $f(x)$를 설계할때 관측자료 $x_i$를 사용하였다는 점이다. 퓨리에 변환이 $f(x)$를 가정하는 방식
\begin{align}
f(x)=\beta_0 + \beta_1 e^{i\omega x}+ \beta_2 e^{i\omega 2x}+ \dots  
\end{align}
과 비교하여 보면 퓨리에변환은 $f(x)$를 표현하는데 무한대에 가까운 숫자의 basis를 사용하였지만 입력자료 $x_i$를 basis에 활용하지는 않았다. 이처럼 입력값 $x_i$를 직접 basis를 설계하는데 활용하는 방식을 non-parametric이라고 한다. 

--- 
### 파라메트릭 모델링에서 Basis 확장

- 지금까지 살펴본 것은 모두 입력변수가 1차원일 경우에 basis를 선택하는 방법이었다. 즉 입력변수의 차원이 $p$라면, 즉 ${\bf x}_ i=cbind(x_ {i1},\dots,x_ {ip})$라면 어떻게 해야하는가? 이와 같은 경우 기저를 어떻게 잡아야 할까? 보통 이런 경우는 **(1)** 일차원 기저를 적당히 확장하여 고차원 기저를 만드는 경우가 있고 **(2)** 커널처럼 자료를 직접활용하여 기저를 만드는 방법이 있다. (1)과 같은 방법은 파라메트릭의 정신을 계승하는 것이고 (semi-parametric 포함) (2)와 같은 방법은 넌파라메트릭의 정신을 계승하는 것이다. 

- 이중에서 (1)의 방법을 살펴보자. (1)의 방법을 주장하는 사람은 크게 다시 2부류로 나누어진다. **(a)** 그 중 하나의 부류는 **멀티플리케이티브 모델**(multiplicative model)을 지지하는 부류이다. 이 사람들은 고차원베이시스를 1차원베이시스들의 product로 표현할 수 있다는 관점이다. 쉽게 말하면 교호작용을 고려하는 모델로 볼 수 있다. 예를들어 입력변수가 4차원이고, 즉 ${\bf x}_ i=cbind(x_{i1},x_{i2},x_{i3},x{i4})$이고 각 차원을 모델링하는데 각각 2개의 파라메터를 쓰고 있다고 생각하자. (additive model) 고차원베이시스를 1차원베이시스의 합으로 표현할 수 있다는 관점임. 
  
- 이때 multiplicative model이 골때린다. 이 모델은 쉽게 말하면 교호작용을 고려하는 모델로 볼 수있다. 예를들어 입력변수 ${\bf x}$가 4차원이고 각 차원을 2개의 파라메터(예를들면 $[1,x]$)로 표현하고 있으면 전체 필요한 파라메터 수는 $2^4$이다. 만약에 입력변수의 차원이 $10$이라고 하면 각 변수당 2개의 파라메터를 쓸때 $2^{10}=1024$개의 파라메터가 필요하다. 한마디로 망한 모델이라는 소리이다. 이처럼 입력변수의 차원에 대하여 파라메터의 수가 지수적으로 증가하는 현상을 차원의 저주라고 부른다. 그래서 일반적으로 Multiplicative model보다 Additive model을 고려하는 것이 좋다. 

- 이제 (2)의 방법은 살펴보자. 이처럼 일반적으로 입력변수가 고차원일때에는 커널과 같은 넌파라메트릭 모델을 고려하는것이 차원의 저주를 피하기에 유리하다. 커널과 같은 경우를 예로 들어보자. $\\{ {\bf x} \\}_ {i=1}^{n}$를 관측하였다면, 
\begin{align}
f({\bf x})=\sum_{i=1}^{n} \theta_i K_h({\bf x},{\bf x}_ i)
\end{align}
와 같이 쓸 수 있다. 이때 
\begin{align}
{\bf x}_ i=[x11_i,x12_i,x21_i,x22_i]
\end{align}
이다. 입력변수의 차원에 상관없이 $n$개의 basis만 가지고서 $f({\bf x})$를 표현 할 수 있다. 

- 커널방법의 또 다른 장점은 $K({\bf x},{\bf x}_ i)$만 잘정의하면 어떠한 입력형태 $\bf x$에서도 동작한다는 것이다. 예를들면 입력 $\bf x$가 문자열, 트리, 그래프등인 경우에도 동작한다. 

- 지금까지 살펴본 모델은 모두 선형모델이다. 선형모델이라는 뜻은 $f(x)$를 아래와 같은 방식으로 표현한다는 의미이다. 
\begin{align}
f(x)=\sum coef \times basis 
\end{align}
여기에서 coef는 parameter로 이해해도 된다. 왜 우리는 선형모델을 가정할까? 선형모델을 가정하면 최소제곱법과 같은 방법을 활용하여 parameter를 매우 쉬운 연산만으로 구할 수 있다는 장점이 있다. 앞에서 살펴본 커널의 경우도 밴드윗을 $h$로 고정하고 중심도 $x_i$로 고정된 상태에서 $\theta_i$를 구하는것은 선형모델이다. (하지만 만약에 커널모델에서 $h$와 $\theta_i$를 동시에 구해야 한다면 이것은 비선형 방정식을 풀어야한다.)  

---

### 비선형모델링 
