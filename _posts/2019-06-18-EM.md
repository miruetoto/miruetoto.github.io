---
layout: post
title: (정리) EM 알고리즘
--- 

### About this doc 

- 여기에서는 EM 알고리즘에 대하여 다룬다. 

### Mixture model 

#### EXAMPLE 1
- 아래와 같은 자료를 고려하자. 
\begin{align}
Z_i=W_iX_i + (1-W_i)Y_i, \quad i=1,\dots,n 
\end{align}
아래를 가정하자. <br/><br/>
**(1)** 모든 관측치는 서로 독립이다. <br/>
**(2)** $W_i$ 는 확률이 $p$인 베르누이 분포에서 생성되었다. <br/>
**(3)** $X_i$ 와 $Y_i$ 는 각각 평균이 $\lambda_1$, $\lambda_2$ 인 포아송분포에서 생성되었다. 

- 관측된 자료는 $\bf z$ 이고 관측하고 싶었던 자료, 즉 완전한 자료는 $\bf (z,w)$이다. 완전한 자료가 $\bf (x,y,w)$ 가 아님을 유의하자. 우리가 알고 싶은 것은 $(\lambda_1,\lambda_2,p)$ 이다. 이제$(\lambda_1,\lambda_2,p)$ 의 MLE를 구하기 위해서 $(\lambda_1,\lambda_2,p)$ 의 우도함수 $L(\lambda_1,\lambda_2,p)$ 를 생각하자. $(\lambda_1,\lambda_2,p)$ 의 우도함수는 $\bf(z,w)$의 **조인트-pdf** 이므로 
\begin{align}
f({\bf z,w})=f({\bf w}) f({\bf z | \bf w})=\prod_{i=1}^{n}f(w_i)f(z_i|w_i)
\end{align}
이제 $f(w_i)$ 와 $f(z_i|w_i)$ 를 구해야 한다. 각각은 아래와 같이 풀 수 있다. <br/><br/>
**(1)** $f(w_i)=p^{w_i}+(1-p)^{1-w_i}$ <br/>
**(2)** $f(z_i|w_i)=
\begin{cases} 
\frac{e^{-\lambda_1} \labmda_1^{z_i}}{z_i !} & w_i=1 \\\\ 
\frac{e^{-\lambda_2} \labmda_2^{z_i}}{z_i !} & w_i=0
\end{cases}$ <br/><br/> 
여기에서 $f(z_i)$ 는 다소 직관적으로 구했다. 
